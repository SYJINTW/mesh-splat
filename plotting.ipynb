{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2b7f6f",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb04c33",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bfbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95728ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- setting start ------------------------------ #\n",
    "# color\n",
    "color_palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "errorbar_color = \"#3A3A3A\"\n",
    "\n",
    "# font\n",
    "csfont = {'family':'Times New Roman', 'serif': 'Times' , 'size' : 23}\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', **csfont)\n",
    "\n",
    "\n",
    "# bar plot size\n",
    "bar_width = 0.4\n",
    "bar_btw_space = 0.04\n",
    "bar_space = 0.2\n",
    "\n",
    "# errorbar plot size\n",
    "err_lw=1.5\n",
    "err_capsize=4\n",
    "err_capthick=1.5\n",
    "\n",
    "# set fig size\n",
    "figsize=(6.4, 4.8)\n",
    "# -------------------------------- setting end ------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCENE_NAME_LIST = ['drjohnson-dw50', 'bicycle-dw50', 'ship',  'mic','ficus', 'lego' ,'hotdog']\n",
    "SCENE_NAME_LIST = ['hotdog', 'lego','ficus', 'mic'  ,'ship' ,'drjohnson-dw50', 'bicycle-dw50']\n",
    "\n",
    "\n",
    "# complexity by 3dgs num :[?, ?, 325316, 307307]\n",
    "\n",
    "def set_metric_ylim_fig(ax, metric_key, scene_name):\n",
    "    \"\"\"\n",
    "    Set fixed y-axis limits for different metrics to ensure consistency across plots.\n",
    "    \n",
    "    Args:\n",
    "        ax: matplotlib axes object\n",
    "        metric_key: string, one of 'PSNR', 'SSIM', 'LPIPS'\n",
    "    \"\"\"\n",
    "    \n",
    "    # for outdoor scene (NeRF MIP360)\n",
    "    if 'bicycle' in scene_name:\n",
    "        if metric_key == 'PSNR':\n",
    "            ax.set_ylim(20, 24)\n",
    "        elif metric_key == 'SSIM':\n",
    "            ax.set_ylim(0.35, 0.65)\n",
    "        elif metric_key == 'LPIPS':\n",
    "            pass\n",
    "            # ax.set_ylim(0, 0.2)\n",
    "    elif 'drjohnson' in scene_name:\n",
    "        pass\n",
    "    # for synthetic scenes (NeRF blender)\n",
    "    else: \n",
    "        if metric_key == 'PSNR':\n",
    "            ax.set_ylim(24.5, 35.0)\n",
    "        elif metric_key == 'SSIM':\n",
    "            ax.set_ylim(0.8, 1.0)\n",
    "        elif metric_key == 'LPIPS':\n",
    "            # ax.set_ylim(0, 0.2)\n",
    "            pass\n",
    "    \n",
    "def set_metric_ylim_delta(ax, metric_key):\n",
    "    \"\"\"\n",
    "    Set fixed y-axis limits for delta plots.\n",
    "    \n",
    "    Args:\n",
    "        ax: matplotlib axes object\n",
    "        metric_key: string, one of 'PSNR', 'SSIM', 'LPIPS'\n",
    "    \"\"\"\n",
    "    if metric_key == 'PSNR':\n",
    "        ax.set_ylim(-0.5, 5.5)  # Delta range for PSNR improvement\n",
    "    elif metric_key == 'SSIM':\n",
    "        ax.set_ylim(-0.01, 0.10)  # Delta range for SSIM improvement\n",
    "    elif metric_key == 'LPIPS':\n",
    "        # ax.set_ylim(-0.15, 0.01)  # Delta range for LPIPS improvement (lower is better)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a298c",
   "metadata": {},
   "source": [
    "## Figure Budget Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def budget_policy_curves():\n",
    "    \"\"\"\n",
    "    Plot metrics vs budget for different budgeting policies.\n",
    "    \"\"\"\n",
    "    ITERATION = 'ours_15000'\n",
    "    MESH_ITERATION = 'ours_1'\n",
    "    \n",
    "    input_dir = Path('./data') / SCENE_NAME\n",
    "    output_dir = Path('./plots') / 'budget_policy_curves' / SCENE_NAME\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define policies with their configurations\n",
    "    policies = [\n",
    "        {'name': 'distortion', 'label': 'Distortion', 'marker': 's', 'color': color_palette[2]},\n",
    "        {'name': 'planarity2', 'label': 'Planarity', 'marker': '1', 'color': color_palette[4]},\n",
    "        {'name': 'area', 'label': 'Area', 'marker': 'o', 'color': color_palette[1]},\n",
    "        {'name': 'uniform', 'label': 'Uniform', 'marker': '^', 'color': color_palette[3]},\n",
    "        # {'name': 'mixed_v1g3', 'label': 'Mixed vis1:geo3', 'marker': '1', 'color': color_palette[4]},\n",
    "        # {'name': 'mixed_v2g2', 'label': 'Mixed vis1:geo1', 'marker': '2', 'color': color_palette[5]},\n",
    "        # {'name': 'mixed_v3g1', 'label': 'Mixed vis3:geo1', 'marker': '3', 'color': color_palette[6]},\n",
    "    ]\n",
    "    \n",
    "    budgets = [40000, 80000, 160000, 320000, 640000]\n",
    "    \n",
    "    metrics = {\n",
    "        'PSNR': {'ylabel': 'PSNR (dB)', 'title': 'PSNR'},\n",
    "        'SSIM': {'ylabel': 'SSIM', 'title': 'SSIM'},\n",
    "        'LPIPS': {'ylabel': 'LPIPS', 'title': 'LPIPS'},\n",
    "    }\n",
    "    \n",
    "    for metric_key, metric_info in metrics.items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. Get Pure mesh baseline\n",
    "        mesh_mean = None\n",
    "        mesh_stderr = None\n",
    "        \n",
    "        mesh_file = input_dir / 'area_1_occlusion' / 'per_view_gs_mesh.json'\n",
    "        if mesh_file.exists():\n",
    "            with open(mesh_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            iter_key = MESH_ITERATION if MESH_ITERATION in data else ITERATION\n",
    "            \n",
    "            if iter_key in data:\n",
    "                metric_data = data[iter_key][metric_key]\n",
    "                if isinstance(metric_data, dict):\n",
    "                    values = [v for v in metric_data.values() if v != -1.0]\n",
    "                else:\n",
    "                    values = [metric_data]\n",
    "                \n",
    "                mesh_mean = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "                mesh_stderr = std_val / np.sqrt(len(values))\n",
    "                print(f\"Pure Mesh - {metric_key}: mean={mesh_mean:.4f}, std={std_val:.4f}, n={len(values)}\")\n",
    "        \n",
    "        # 2. Process each policy\n",
    "        for policy in policies:\n",
    "            policy_name = policy['name']\n",
    "            xs = []\n",
    "            ys = []\n",
    "            errs = []\n",
    "            \n",
    "            # Add pure mesh point at budget=0\n",
    "            if mesh_mean is not None:\n",
    "                xs.append(0)\n",
    "                ys.append(mesh_mean)\n",
    "                errs.append(mesh_stderr)\n",
    "            \n",
    "            print(f\"\\nProcessing {policy['label']}:\")\n",
    "            for budget in budgets:\n",
    "                policy_file = input_dir / f\"{policy_name}_{budget}_occlusion\" / 'per_view_gs_mesh.json'\n",
    "                \n",
    "                if policy_file.exists():\n",
    "                    with open(policy_file, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    if ITERATION in data:\n",
    "                        metric_data = data[ITERATION][metric_key]\n",
    "                        if isinstance(metric_data, dict):\n",
    "                            values = [v for v in metric_data.values() if v != -1.0]\n",
    "                        else:\n",
    "                            values = [metric_data]\n",
    "                        \n",
    "                        mean_val = np.mean(values)\n",
    "                        std_val = np.std(values)\n",
    "                        stderr = std_val / np.sqrt(len(values))\n",
    "                        num_splats = data[ITERATION].get('num_splats', budget)\n",
    "                        \n",
    "                        xs.append(num_splats)\n",
    "                        ys.append(mean_val)\n",
    "                        errs.append(stderr)\n",
    "                        \n",
    "                        print(f\"  Budget {budget}: mean={mean_val:.4f}, std={std_val:.4f}, splats={num_splats}\")\n",
    "            \n",
    "            # Plot this policy\n",
    "            if xs:\n",
    "                print(f\"  Plotting {len(xs)} points for {policy['label']}\")\n",
    "                ax.errorbar(xs, ys, yerr=errs,\n",
    "                           marker=policy['marker'], markersize=8, linewidth=2.5,\n",
    "                           capsize=err_capsize, capthick=err_capthick,\n",
    "                           color=policy['color'], label=policy['label'], zorder=2)\n",
    "            else:\n",
    "                print(f\"  No data to plot for {policy['label']}!\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Bit Budget (\\#Gaussians)', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        \n",
    "        set_metric_ylim_fig(ax, metric_key, SCENE_NAME)\n",
    "        \n",
    "        # Format x-axis to show values in K (thousands)\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K' if x > 0 else '0'))\n",
    "        \n",
    "        \n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        base_name = f'{metric_key}_vs_budget_{SCENE_NAME}'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\nSaved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# [TODO] [NOTE] fix y-axis range to enable comparison across plots\n",
    "# the exact ranges for each set of figures might differ\n",
    "\n",
    "# SCENE_NAME = 'lego'\n",
    "# budget_policy_curves()\n",
    "\n",
    "\n",
    "for name in SCENE_NAME_LIST:\n",
    "    SCENE_NAME = name\n",
    "    budget_policy_curves()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b73a6",
   "metadata": {},
   "source": [
    "## Allocation Distribution Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_allocation_distribution(policy_file_path):\n",
    "    \"\"\"\n",
    "    Plot allocation distribution figure.\n",
    "    Sort according to number of allocated gaussians.\n",
    "    Plot both CDF and PMF.\n",
    "    \n",
    "    Args:\n",
    "        policy_file_path: Path to .npy file containing allocation array\n",
    "                         e.g., 'data/lego/area_640000_occlusion/area_640000.npy'\n",
    "    \"\"\"\n",
    "    # Load allocation data\n",
    "    allocation = np.load(policy_file_path)\n",
    "    \n",
    "    # Sort by number of allocated gaussians (descending order)\n",
    "    sorted_allocation = np.sort(allocation)[::-1]\n",
    "    \n",
    "    # Create figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Plotting Allocation Distribution\")\n",
    "    print(f\"File: {policy_file_path}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total mesh faces: {len(allocation)}\")\n",
    "    print(f\"Total gaussians allocated: {np.sum(allocation)}\")\n",
    "    print(f\"Mean gaussians per face: {np.mean(allocation):.2f}\")\n",
    "    print(f\"Median gaussians per face: {np.median(allocation):.2f}\")\n",
    "    print(f\"Max gaussians per face: {np.max(allocation)}\")\n",
    "    print(f\"Min gaussians per face: {np.min(allocation)}\")\n",
    "    \n",
    "    # --- Plot 1: PMF (Probability Mass Function) ---\n",
    "    # Create histogram\n",
    "    bins = np.arange(0, np.max(sorted_allocation) + 2) - 0.5\n",
    "    counts, bin_edges = np.histogram(sorted_allocation, bins=bins)\n",
    "    pmf = counts / len(sorted_allocation)\n",
    "    \n",
    "    # Bar plot for PMF\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    ax1.bar(bin_centers, pmf, width=0.8, \n",
    "            color=color_palette[0], alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    ax1.set_xlabel('Number of Gaussians per Face', fontsize=20)\n",
    "    ax1.set_ylabel('Probability Mass', fontsize=20)\n",
    "    ax1.set_title('PMF of Gaussian Allocation', fontsize=20)\n",
    "    ax1.tick_params(labelsize=18)\n",
    "    ax1.set_axisbelow(True)\n",
    "    \n",
    "    # --- Plot 2: CDF (Cumulative Distribution Function) ---\n",
    "    # Calculate CDF\n",
    "    sorted_unique = np.unique(sorted_allocation)\n",
    "    cdf = np.array([np.sum(sorted_allocation <= val) / len(sorted_allocation) \n",
    "                    for val in sorted_unique])\n",
    "    \n",
    "    # Line plot for CDF\n",
    "    ax2.plot(sorted_unique, cdf, \n",
    "             marker='o', markersize=4, linewidth=2, \n",
    "             color=color_palette[1], label='CDF')\n",
    "    \n",
    "    # Add reference lines\n",
    "    ax2.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='50th percentile')\n",
    "    ax2.axhline(y=0.9, color='gray', linestyle=':', linewidth=1, alpha=0.5, label='90th percentile')\n",
    "    \n",
    "    ax2.set_xlabel('Number of Gaussians per Face', fontsize=20)\n",
    "    ax2.set_ylabel('Cumulative Probability', fontsize=20)\n",
    "    ax2.set_title('CDF of Gaussian Allocation', fontsize=20)\n",
    "    ax2.set_ylim(-0.05, 1.05)\n",
    "    ax2.tick_params(labelsize=18)\n",
    "    ax2.legend(loc='lower right', framealpha=0.9, fontsize=16)\n",
    "    ax2.set_axisbelow(True)\n",
    "    \n",
    "    fig.set_constrained_layout(True)\n",
    "    \n",
    "    # Save figure\n",
    "    policy_path = Path(policy_file_path)\n",
    "    scene_name = policy_path.parent.parent.name\n",
    "    policy_name = policy_path.parent.name\n",
    "    \n",
    "    output_dir = Path('./plots') / 'allocation_distribution' / scene_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    base_name = f'allocation_dist_{policy_name}'\n",
    "    plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "    print(f\"\\nSaved: {base_name}.png and .eps\\n\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# plot_allocation_distribution('data/lego/area_640000_occlusion/area_640000.npy')\n",
    "\n",
    "# Or run for all scenes and policies:\n",
    "def plot_all_allocation_distributions():\n",
    "    \"\"\"Plot allocation distributions for all scenes and policies.\"\"\"\n",
    "    # budgets = [40000, 80000, 160000, 320000, 640000]\n",
    "    budgets = [640000]\n",
    "    \n",
    "    policies = ['area', 'distortion', 'uniform', 'planarity2']\n",
    "    \n",
    "    for scene in ['lego']:\n",
    "        for policy in policies:\n",
    "            for budget in budgets:\n",
    "                npy_path = Path('./data') / scene / f'{policy}_{budget}_occlusion' / f'{policy}_{budget}.npy'\n",
    "                if npy_path.exists():\n",
    "                    print(f\"\\nProcessing {scene} - {policy} - {budget}\")\n",
    "                    plot_allocation_distribution(npy_path)\n",
    "                else:\n",
    "                    print(f\"[WARN] File not found: {npy_path}\")\n",
    "\n",
    "# Uncomment to run for all:\n",
    "\n",
    "# plot_all_allocation_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights_cdf_pdf(scene_name='lego', policy_name='distortion', normalize=False):\n",
    "    \"\"\"\n",
    "    Plot weight distribution figure for a given scene and policy.\n",
    "    Shows both CDF and PDF (histogram).\n",
    "    \n",
    "    Args:\n",
    "        scene_name: Scene name (e.g., 'lego', 'ficus', 'bicycle-dw50')\n",
    "        policy_name: Policy name (e.g., 'area', 'distortion', 'uniform', 'planarity2')\n",
    "        normalize: If True, normalize weights to sum to 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct path to weights file\n",
    "    weights_dir = Path('./data/weights') / scene_name / 'policy' / 'mesh_milo'\n",
    "    \n",
    "    # Find the weights file for this policy\n",
    "    weights_file = None\n",
    "    for tri_dir in weights_dir.glob('tri_*'):\n",
    "        candidate = tri_dir / policy_name / 'weights.npy'\n",
    "        if candidate.exists():\n",
    "            weights_file = candidate\n",
    "            break\n",
    "    \n",
    "    if weights_file is None:\n",
    "        print(f\"[ERROR] No weights file found for {scene_name} - {policy_name}\")\n",
    "        return\n",
    "    \n",
    "    # Load weights data\n",
    "    weights = np.load(weights_file)\n",
    "    \n",
    "    # Normalize if requested\n",
    "    if normalize:\n",
    "        weights = weights / np.sum(weights)\n",
    "    \n",
    "    # Create figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Plotting Weight Distribution\")\n",
    "    print(f\"Scene: {scene_name}, Policy: {policy_name}\")\n",
    "    print(f\"File: {weights_file}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total mesh faces: {len(weights)}\")\n",
    "    print(f\"Sum of weights: {np.sum(weights):.4f}\")\n",
    "    print(f\"Mean weight: {np.mean(weights):.6f}\")\n",
    "    print(f\"Median weight: {np.median(weights):.6f}\")\n",
    "    print(f\"Std weight: {np.std(weights):.6f}\")\n",
    "    print(f\"Max weight: {np.max(weights):.6f}\")\n",
    "    print(f\"Min weight: {np.min(weights):.6f}\")\n",
    "    \n",
    "    # Calculate percentiles for better x-axis limits\n",
    "    p99 = np.percentile(weights, 99)\n",
    "    p95 = np.percentile(weights, 95)\n",
    "    p90 = np.percentile(weights, 90)\n",
    "    \n",
    "    print(f\"90th percentile: {p90:.6f}\")\n",
    "    print(f\"95th percentile: {p95:.6f}\")\n",
    "    print(f\"99th percentile: {p99:.6f}\")\n",
    "    \n",
    "    # --- Plot 1: PDF (Probability Density Function) - Histogram ---\n",
    "    # Use percentile-based x-limit to focus on the main distribution\n",
    "    # Show up to 99th percentile to exclude extreme outliers\n",
    "    xlim_max = p99 * 1.1  # Add 10% padding\n",
    "    \n",
    "    # Filter weights for histogram to focus on main distribution\n",
    "    weights_filtered = weights[weights <= xlim_max]\n",
    "    \n",
    "    n_bins = 50\n",
    "    counts, bin_edges, patches = ax1.hist(weights_filtered, bins=n_bins, \n",
    "                                           density=True,\n",
    "                                           color=color_palette[0], \n",
    "                                           alpha=0.7, \n",
    "                                           edgecolor='black', \n",
    "                                           linewidth=0.5)\n",
    "    \n",
    "    ax1.set_xlabel('Weight Value', fontsize=20)\n",
    "    ax1.set_ylabel('Probability Density', fontsize=20)\n",
    "    ax1.set_title('PDF of Policy Weights', fontsize=20)\n",
    "    ax1.set_xlim(0, xlim_max)\n",
    "    ax1.tick_params(labelsize=18)\n",
    "    ax1.set_axisbelow(True)\n",
    "    \n",
    "    # Add mean and median lines\n",
    "    mean_weight = np.mean(weights)\n",
    "    median_weight = np.median(weights)\n",
    "    \n",
    "    if mean_weight <= xlim_max:\n",
    "        ax1.axvline(x=mean_weight, color='red', linestyle='--', \n",
    "                    linewidth=2, label=f'Mean: {mean_weight:.4f}')\n",
    "    if median_weight <= xlim_max:\n",
    "        ax1.axvline(x=median_weight, color='orange', linestyle=':', \n",
    "                    linewidth=2, label=f'Median: {median_weight:.4f}')\n",
    "    \n",
    "    ax1.legend(loc='best', framealpha=0.9, fontsize=16)\n",
    "    \n",
    "    # --- Plot 2: CDF (Cumulative Distribution Function) ---\n",
    "    sorted_weights = np.sort(weights)\n",
    "    cdf = np.arange(1, len(sorted_weights) + 1) / len(sorted_weights)\n",
    "    \n",
    "    # Line plot for CDF\n",
    "    ax2.plot(sorted_weights, cdf, \n",
    "             linewidth=2, \n",
    "             color=color_palette[1], \n",
    "             label='CDF')\n",
    "    \n",
    "    # Add reference lines at percentiles\n",
    "    ax2.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5, \n",
    "                label='50th percentile')\n",
    "    ax2.axhline(y=0.9, color='gray', linestyle=':', linewidth=1, alpha=0.5, \n",
    "                label='90th percentile')\n",
    "    ax2.axhline(y=0.95, color='gray', linestyle='-.', linewidth=1, alpha=0.5, \n",
    "                label='95th percentile')\n",
    "    \n",
    "    # Add vertical line at median\n",
    "    ax2.axvline(x=median_weight, color='orange', linestyle=':', linewidth=2, \n",
    "                label=f'Median: {median_weight:.4f}')\n",
    "    \n",
    "    ax2.set_xlabel('Weight Value', fontsize=20)\n",
    "    ax2.set_ylabel('Cumulative Probability', fontsize=20)\n",
    "    ax2.set_title(f'CDF of Policy Weights {policy_name}', fontsize=20)\n",
    "    ax2.set_xlim(0, xlim_max)\n",
    "    ax2.set_ylim(-0.05, 1.05)\n",
    "    ax2.tick_params(labelsize=18)\n",
    "    ax2.legend(loc='lower right', framealpha=0.9, fontsize=14)\n",
    "    ax2.set_axisbelow(True)\n",
    "    \n",
    "    fig.set_constrained_layout(True)\n",
    "    \n",
    "    # Save figure\n",
    "    output_dir = Path('./plots') / 'weight_distribution' / scene_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    base_name = f'weights_dist_{policy_name}'\n",
    "    if normalize:\n",
    "        base_name += '_normalized'\n",
    "    \n",
    "    plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "    print(f\"\\nSaved: {base_name}.png and .eps\\n\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_all_weight_distributions():\n",
    "    \"\"\"Plot weight distributions for all available scene-policy combinations.\"\"\"\n",
    "    \n",
    "    weights_base = Path('./data/weights')\n",
    "    \n",
    "    # Scene to policy mapping (based on what's available)\n",
    "    scene_policies = {\n",
    "        'lego': ['area', 'distortion', 'planarity2'],\n",
    "        'ficus': ['area', 'distortion', 'planarity2'],\n",
    "        'hotdog': ['area', 'distortion', 'planarity2'],\n",
    "        'mic': ['area', 'distortion', 'planarity2'],\n",
    "        'ship': ['area', 'distortion', 'planarity2'],\n",
    "        'bicycle-dw50': ['area', 'distortion', 'planarity2'],\n",
    "        'drjohnson-dw50': ['area', 'distortion', 'planarity2'],\n",
    "    }\n",
    "    \n",
    "    for scene, policies in scene_policies.items():\n",
    "        scene_dir = weights_base / scene / 'policy' / 'mesh_milo'\n",
    "        \n",
    "        if not scene_dir.exists():\n",
    "            print(f\"[WARN] Scene directory not found: {scene_dir}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"Processing scene: {scene}\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        for policy in policies:\n",
    "            # Check if this policy exists for this scene\n",
    "            found = False\n",
    "            for tri_dir in scene_dir.glob('tri_*'):\n",
    "                if (tri_dir / policy / 'weights.npy').exists():\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if found:\n",
    "                plot_weights_cdf_pdf(scene, policy)\n",
    "            else:\n",
    "                print(f\"[SKIP] No weights found for {scene} - {policy}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Plot single scene-policy combination\n",
    "# plot_weights_cdf_pdf('lego', 'distortion')\n",
    "\n",
    "# Or plot all available combinations\n",
    "# plot_all_weight_distributions()\n",
    "\n",
    "\n",
    "# SCENE='lego'\n",
    "# budget_policy_curves()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad36f1",
   "metadata": {},
   "source": [
    "## Figure Delta (DTGS - Pure Mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def policy_budget_delta_curves():\n",
    "    \"\"\"\n",
    "    Plot average delta (improvement over pure mesh) across all scenes.\n",
    "    \n",
    "    Average across all nerf-synthetic scenes \n",
    "    (the 5 scenes we used are ficus, hotdog, lego, mic, ship)\n",
    "    x-axis: budget number (0, 40k, 80k, 160k, 320k, 640k)\n",
    "    y-axis: delta of quality in PSNR/SSIM/LPIPS (compared to pure mesh baseline)\n",
    "    hue: different budgeting policies\n",
    "    \"\"\"\n",
    "    ITERATION = 'ours_15000'\n",
    "    MESH_ITERATION = 'ours_1'\n",
    "    \n",
    "    budgets = [40000, 80000, 160000, 320000, 640000]\n",
    "    \n",
    "    # Define policies with their configurations\n",
    "    policies = [\n",
    "        {'name': 'area', 'label': 'Area-based', 'marker': 'o', 'color': color_palette[1]},\n",
    "        {'name': 'distortion', 'label': 'Distortion-based', 'marker': 's', 'color': color_palette[2]},\n",
    "        {'name': 'uniform', 'label': 'Uniform', 'marker': '^', 'color': color_palette[3]},\n",
    "        {'name': 'planarity2', 'label': 'Planarity', 'marker': '1', 'color': color_palette[4]},\n",
    "        # {'name': 'mixed_v1g3', 'label': 'Mixed vis1:geo3', 'marker': '1', 'color': color_palette[4]},\n",
    "        # {'name': 'mixed_v2g2', 'label': 'Mixed vis1:geo1', 'marker': '2', 'color': color_palette[5]},\n",
    "        # {'name': 'mixed_v3g1', 'label': 'Mixed vis3:geo1', 'marker': '3', 'color': color_palette[6]},\n",
    "    ]\n",
    "    \n",
    "    input_base = Path('./data')\n",
    "    output_dir = Path('./plots') / 'budget_policy_delta_curves'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    metrics = {\n",
    "        'PSNR': {'ylabel': r'$\\Delta$ in PSNR (dB)', 'title': 'PSNR Improvement'},\n",
    "        'SSIM': {'ylabel': r'$\\Delta$ in SSIM', 'title': 'SSIM Improvement'},\n",
    "        'LPIPS': {'ylabel': r'$\\Delta$ LPIPS', 'title': 'LPIPS Improvement'}\n",
    "    }\n",
    "    \n",
    "    # For each metric, create one plot\n",
    "    for metric_key, metric_info in metrics.items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Computing Average Delta for {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Store data for each policy\n",
    "        policy_data = {p['name']: {'xs': [], 'ys': [], 'errs': []} for p in policies}\n",
    "        \n",
    "        # For each budget level\n",
    "        for budget in budgets:\n",
    "            print(f\"\\nProcessing budget: {budget}\")\n",
    "            \n",
    "            # Collect deltas for each policy across all scenes\n",
    "            policy_deltas = {p['name']: [] for p in policies}\n",
    "            \n",
    "            for scene in SCENE_NAME_LIST:\n",
    "                scene_dir = input_base / scene\n",
    "                \n",
    "                # Get pure mesh baseline for this scene\n",
    "                mesh_file = scene_dir / 'area_1_occlusion' / 'per_view_gs_mesh.json'\n",
    "                \n",
    "                if not mesh_file.exists():\n",
    "                    print(f\"  [WARN] Missing mesh file for {scene}\")\n",
    "                    continue\n",
    "                \n",
    "                with open(mesh_file, 'r') as f:\n",
    "                    mesh_data = json.load(f)\n",
    "                \n",
    "                iter_key = MESH_ITERATION if MESH_ITERATION in mesh_data else ITERATION\n",
    "                \n",
    "                if iter_key not in mesh_data:\n",
    "                    print(f\"  [WARN] No iteration key found in mesh file for {scene}\")\n",
    "                    continue\n",
    "                \n",
    "                # Get baseline metric value\n",
    "                mesh_metric = mesh_data[iter_key][metric_key]\n",
    "                if isinstance(mesh_metric, dict):\n",
    "                    mesh_values = [v for v in mesh_metric.values() if v != -1.0]\n",
    "                    baseline = np.mean(mesh_values)\n",
    "                else:\n",
    "                    baseline = mesh_metric\n",
    "                \n",
    "                # For each policy, compute delta\n",
    "                for policy in policies:\n",
    "                    policy_name = policy['name']\n",
    "                    policy_file = scene_dir / f'{policy_name}_{budget}_occlusion' / 'per_view_gs_mesh.json'\n",
    "                    \n",
    "                    if not policy_file.exists():\n",
    "                        print(f\"  [WARN] Missing {policy_name} file for {scene} at budget {budget}\")\n",
    "                        continue\n",
    "                    \n",
    "                    with open(policy_file, 'r') as f:\n",
    "                        policy_file_data = json.load(f)\n",
    "                    \n",
    "                    if ITERATION not in policy_file_data:\n",
    "                        print(f\"  [WARN] No {ITERATION} in {policy_name} file for {scene}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Get policy metric value\n",
    "                    policy_metric = policy_file_data[ITERATION][metric_key]\n",
    "                    if isinstance(policy_metric, dict):\n",
    "                        policy_values = [v for v in policy_metric.values() if v != -1.0]\n",
    "                        policy_val = np.mean(policy_values)\n",
    "                    else:\n",
    "                        policy_val = policy_metric\n",
    "                    \n",
    "                    # Compute delta (improvement over baseline)\n",
    "                    # For LPIPS, lower is better\n",
    "                    delta = policy_val - baseline  # Positive = improvement\n",
    "                    \n",
    "                    policy_deltas[policy_name].append(delta)\n",
    "                    print(f\"  {scene} {policy_name}: baseline={baseline:.4f}, policy={policy_val:.4f}, delta={delta:.4f}\")\n",
    "            \n",
    "            # Compute average delta and standard error across scenes\n",
    "            for policy in policies:\n",
    "                policy_name = policy['name']\n",
    "                if len(policy_deltas[policy_name]) > 0:\n",
    "                    deltas = np.array(policy_deltas[policy_name])\n",
    "                    mean_delta = np.mean(deltas)\n",
    "                    std_delta = np.std(deltas)\n",
    "                    stderr_delta = std_delta / np.sqrt(len(deltas))\n",
    "                    \n",
    "                    policy_data[policy_name]['xs'].append(budget)\n",
    "                    policy_data[policy_name]['ys'].append(mean_delta)\n",
    "                    policy_data[policy_name]['errs'].append(stderr_delta)\n",
    "                    \n",
    "                    print(f\"  {policy_name} average: mean={mean_delta:.4f}, std={std_delta:.4f}, n={len(deltas)}\")\n",
    "        \n",
    "        # Add budget=0 point (delta=0 by definition)\n",
    "        for policy in policies:\n",
    "            policy_name = policy['name']\n",
    "            if len(policy_data[policy_name]['xs']) > 0:\n",
    "                policy_data[policy_name]['xs'].insert(0, 0)\n",
    "                policy_data[policy_name]['ys'].insert(0, 0.0)\n",
    "                policy_data[policy_name]['errs'].insert(0, 0.0)\n",
    "        \n",
    "        # Plot each policy\n",
    "        for policy in policies:\n",
    "            policy_name = policy['name']\n",
    "            if len(policy_data[policy_name]['xs']) > 0:\n",
    "                ax.errorbar(\n",
    "                    policy_data[policy_name]['xs'], \n",
    "                    policy_data[policy_name]['ys'], \n",
    "                    yerr=policy_data[policy_name]['errs'],\n",
    "                    marker=policy['marker'], \n",
    "                    markersize=8, \n",
    "                    linewidth=2.5,\n",
    "                    capsize=err_capsize, \n",
    "                    capthick=err_capthick,\n",
    "                    color=policy['color'], \n",
    "                    label=policy['label'], \n",
    "                    zorder=2\n",
    "                )\n",
    "                print(f\"\\n[INFO] Plotted {len(policy_data[policy_name]['xs'])} points for {policy['label']}\")\n",
    "        \n",
    "        # Add horizontal line at y=0 (no improvement)\n",
    "        ax.axhline(y=0, color='gray', linestyle='--', linewidth=1, alpha=0.5, zorder=1)\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Bit Budget (\\#Gaussians)', fontsize=20)\n",
    "        ax.set_ylabel(metric_info['ylabel'], fontsize=20)\n",
    "        \n",
    "        # Set fixed y-axis range\n",
    "        set_metric_ylim_delta(ax, metric_key)\n",
    "        \n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K' if x > 0 else '0'))\n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        # Save both formats\n",
    "        base_name = f'{metric_key}_delta_vs_budget_average'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\n[INFO] Saved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "policy_budget_delta_curves()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c54ab1",
   "metadata": {},
   "source": [
    "## Fig Renderer Comparison\n",
    "\n",
    "compare DTGS, TGS, GaMeS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_renderer_comp():\n",
    "    \"\"\"\n",
    "    Compare different renderer/training pipelines (DTGS, TGS, GaMeS)\n",
    "    under same budget/scene using uniform policy.\n",
    "    \n",
    "    the renderer used consistently in training and evaluation\n",
    "    \n",
    "    \n",
    "    x-axis: bit budget in #Gaussians (40k, 80k, 160k, 320k, 640k)\n",
    "    y-axis: quality in PSNR/SSIM/LPIPS\n",
    "    hue: [DTGS (ours), TGS (ours), GaMeS]\n",
    "    \"\"\"\n",
    "    ITERATION = 'ours_15000'\n",
    "    MESH_ITERATION = 'ours_1'\n",
    "    POLICY = 'uniform'\n",
    "    \n",
    "    input_dir = Path('./data')\n",
    "    games_dir = Path('./data/games_results')\n",
    "    output_dir = Path('./plots') / 'renderer_comp' / SCENE_NAME\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define renderers/pipelines with their configurations\n",
    "    renderers = [\n",
    "        {'name': 'dtgs', 'label': 'DTGS (Ours)', 'marker': 'o', 'color': color_palette[0], \n",
    "         'is_games': False},\n",
    "        {'name': 'tgs', 'label': 'TGS (Ours)', 'marker': 's', 'color': color_palette[1], \n",
    "         'is_games': False},\n",
    "        {'name': 'games', 'label': 'GaMeS', 'marker': '^', 'color': color_palette[2], \n",
    "         'is_games': True},\n",
    "    ]\n",
    "    \n",
    "    budgets = [40000, 80000, 160000, 320000, 640000]\n",
    "    \n",
    "    metrics = {\n",
    "        'PSNR': {'ylabel': 'PSNR (dB)', 'title': 'PSNR'},\n",
    "        'SSIM': {'ylabel': 'SSIM', 'title': 'SSIM'},\n",
    "        'LPIPS': {'ylabel': 'LPIPS', 'title': 'LPIPS'},\n",
    "    }\n",
    "    \n",
    "    for metric_key, metric_info in metrics.items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting {metric_key} - Renderer Comparison for {SCENE_NAME}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. Get Pure mesh baseline (shared across all renderers)\n",
    "        mesh_mean = None\n",
    "        mesh_stderr = None\n",
    "        \n",
    "        mesh_file = input_dir / SCENE_NAME / 'area_1_occlusion' / 'per_view_gs_mesh.json'\n",
    "        if mesh_file.exists():\n",
    "            with open(mesh_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            iter_key = MESH_ITERATION if MESH_ITERATION in data else ITERATION\n",
    "            \n",
    "            if iter_key in data:\n",
    "                metric_data = data[iter_key][metric_key]\n",
    "                if isinstance(metric_data, dict):\n",
    "                    values = [v for v in metric_data.values() if v != -1.0]\n",
    "                else:\n",
    "                    values = [metric_data]\n",
    "                \n",
    "                mesh_mean = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "                mesh_stderr = std_val / np.sqrt(len(values))\n",
    "                print(f\"Pure Mesh - {metric_key}: mean={mesh_mean:.4f}, std={std_val:.4f}, n={len(values)}\")\n",
    "        \n",
    "        # Store renderer data for comparison\n",
    "        renderer_data = {r['name']: {'xs': [], 'ys': [], 'errs': []} for r in renderers}\n",
    "        \n",
    "        # 2. Process each renderer\n",
    "        for renderer in renderers:\n",
    "            renderer_name = renderer['name']\n",
    "            is_games = renderer['is_games']\n",
    "            \n",
    "            xs = []\n",
    "            ys = []\n",
    "            errs = []\n",
    "            \n",
    "            # [NOTE] Our x=0 is mesh background, whereas GaMeS is blank\n",
    "            if mesh_mean is not None:\n",
    "                xs.append(0)\n",
    "                if is_games: #GaMeS results do not include pure mesh point\n",
    "                    ys.append( 1 if metric_key=='LPIPS' else 0 )\n",
    "                    errs.append(0)\n",
    "                else: #our DTGS/TGS results include pure mesh point\n",
    "                    ys.append(mesh_mean)\n",
    "                    errs.append(mesh_stderr)\n",
    "            \n",
    "            print(f\"\\nProcessing {renderer['label']}:\")\n",
    "            \n",
    "            for budget in budgets:\n",
    "                # Determine the correct file path\n",
    "                if is_games:\n",
    "                    # GaMeS results are in games_results folder\n",
    "                    scene_dir = games_dir / SCENE_NAME\n",
    "                else:\n",
    "                    # DTGS/TGS results are in main data folder\n",
    "                    scene_dir = input_dir / SCENE_NAME\n",
    "                \n",
    "                if renderer_name == 'dtgs' or renderer_name == 'games':\n",
    "                    policy_file = scene_dir / f'{POLICY}_{budget}_occlusion' / 'per_view_gs_mesh.json'\n",
    "                elif renderer_name == 'tgs':\n",
    "                    policy_file = scene_dir / f'{POLICY}_{budget}_no_occlusion' / 'per_view_gs_mesh.json'\n",
    "                \n",
    "                if policy_file.exists():\n",
    "                    with open(policy_file, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    if ITERATION in data:\n",
    "                        metric_data = data[ITERATION][metric_key]\n",
    "                        if isinstance(metric_data, dict):\n",
    "                            values = [v for v in metric_data.values() if v != -1.0]\n",
    "                        else:\n",
    "                            values = [metric_data]\n",
    "                        \n",
    "                        mean_val = np.mean(values)\n",
    "                        std_val = np.std(values)\n",
    "                        stderr = std_val / np.sqrt(len(values))\n",
    "                        num_splats = data[ITERATION].get('num_splats', budget)\n",
    "                        \n",
    "                        xs.append(num_splats)\n",
    "                        ys.append(mean_val)\n",
    "                        errs.append(stderr)\n",
    "                        \n",
    "                        print(f\"  Budget {budget}: mean={mean_val:.4f}, std={std_val:.4f}, splats={num_splats}\")\n",
    "                else:\n",
    "                    print(f\"  Budget {budget}: File not found - {policy_file}\")\n",
    "            \n",
    "            # Store data for comparison\n",
    "            renderer_data[renderer_name]['xs'] = xs\n",
    "            renderer_data[renderer_name]['ys'] = ys\n",
    "            renderer_data[renderer_name]['errs'] = errs\n",
    "            \n",
    "            # Plot this renderer\n",
    "            if xs:\n",
    "                print(f\"  Plotting {len(xs)} points for {renderer['label']}\")\n",
    "                ax.errorbar(xs, ys, yerr=errs,\n",
    "                           marker=renderer['marker'], markersize=8, linewidth=2.5,\n",
    "                           capsize=err_capsize, capthick=err_capthick,\n",
    "                           color=renderer['color'], label=renderer['label'], zorder=2)\n",
    "            else:\n",
    "                print(f\"  No data to plot for {renderer['label']}!\")\n",
    "        \n",
    "        # Print differences between renderers at each budget\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Renderer Differences for {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Find common budgets (excluding budget=0)\n",
    "        dtgs_budgets = set(renderer_data['dtgs']['xs'][1:])  # Skip x=0\n",
    "        tgs_budgets = set(renderer_data['tgs']['xs'][1:])\n",
    "        games_budgets = set(renderer_data['games']['xs'][1:])\n",
    "        \n",
    "        common_budgets = sorted(dtgs_budgets & tgs_budgets & games_budgets)\n",
    "        \n",
    "        for budget in common_budgets:\n",
    "            # Find indices for this budget\n",
    "            dtgs_idx = renderer_data['dtgs']['xs'].index(budget)\n",
    "            tgs_idx = renderer_data['tgs']['xs'].index(budget)\n",
    "            games_idx = renderer_data['games']['xs'].index(budget)\n",
    "            \n",
    "            dtgs_val = renderer_data['dtgs']['ys'][dtgs_idx]\n",
    "            tgs_val = renderer_data['tgs']['ys'][tgs_idx]\n",
    "            games_val = renderer_data['games']['ys'][games_idx]\n",
    "            \n",
    "            # Calculate differences\n",
    "            # For LPIPS, lower is better, so we flip the sign for interpretation\n",
    "            dtgs_tgs_diff = dtgs_val - tgs_val  # Positive means DTGS is better\n",
    "            dtgs_games_diff = dtgs_val - games_val  # Positive means DTGS is better\n",
    "            \n",
    "            print(f\"\\nBudget {int(budget/1000)}K:\")\n",
    "            print(f\"  DTGS:  {dtgs_val:.4f}\")\n",
    "            print(f\"  TGS:   {tgs_val:.4f}\")\n",
    "            print(f\"  GaMeS: {games_val:.4f}\")\n",
    "            print(f\"  DTGS - TGS:   {dtgs_tgs_diff:+.4f} ({abs(dtgs_tgs_diff/tgs_val*100):.2f}%)\")\n",
    "            print(f\"  DTGS - GaMeS: {dtgs_games_diff:+.4f} ({abs(dtgs_games_diff/games_val*100):.2f}%)\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Bit Budget (\\#Gaussians)', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        \n",
    "        # set_metric_ylim_fig(ax, metric_key, SCENE_NAME)\n",
    "        \n",
    "        # Format x-axis to show values in K (thousands)\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K' if x > 0 else '0'))\n",
    "        \n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        base_name = f'{metric_key}_renderer_comp_{SCENE_NAME}'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\nSaved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Run for all scenes\n",
    "for name in SCENE_NAME_LIST:\n",
    "    SCENE_NAME = name\n",
    "    plot_renderer_comp()\n",
    "\n",
    "SCENE_NAME = 'lego'\n",
    "plot_renderer_comp()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38694a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_renderer_comp_average():\n",
    "    \"\"\"\n",
    "    Compare different renderer/training pipelines (DTGS, TGS, GaMeS)\n",
    "    the renderer used consistently in training and evaluation\n",
    "    averaged across all scenes using uniform policy.\n",
    "    \n",
    "    x-axis: bit budget in #Gaussians (40k, 80k, 160k, 320k, 640k)\n",
    "    y-axis: average quality in PSNR/SSIM/LPIPS across all scenes\n",
    "    hue: [DTGS (ours), TGS (ours), GaMeS]\n",
    "    \"\"\"\n",
    "    ITERATION = 'ours_15000'\n",
    "    MESH_ITERATION = 'ours_1'\n",
    "    POLICY = 'uniform'\n",
    "    \n",
    "    \n",
    "    input_dir = Path('./data')\n",
    "    games_dir = Path('./data/games_results')\n",
    "    output_dir = Path('./plots') / 'renderer_comp_average'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define renderers/pipelines with their configurations\n",
    "    renderers = [\n",
    "        {'name': 'dtgs', 'label': 'DTGS (Ours)', 'marker': 'o', 'color': color_palette[0], \n",
    "         'is_games': False},\n",
    "        # {'name': 'tgs', 'label': 'TGS (Ours)', 'marker': 's', 'color': color_palette[1], \n",
    "        #  'is_games': False},  \n",
    "        {'name': 'games', 'label': 'GaMeS', 'marker': '^', 'color': color_palette[2], \n",
    "         'is_games': True},\n",
    "    ]\n",
    "    \n",
    "    budgets = [40000, 80000, 160000, 320000, 640000]\n",
    "    \n",
    "    metrics = {\n",
    "        'PSNR': {'ylabel': 'PSNR (dB)', 'title': 'PSNR'},\n",
    "        'SSIM': {'ylabel': 'SSIM', 'title': 'SSIM'},\n",
    "        'LPIPS': {'ylabel': 'LPIPS', 'title': 'LPIPS'},\n",
    "    }\n",
    "    \n",
    "    for metric_key, metric_info in metrics.items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Average {metric_key} - Renderer Comparison\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. Get Pure mesh baseline averaged across all scenes\n",
    "        mesh_values_all_scenes = []\n",
    "        \n",
    "        for scene in SCENE_NAME_LIST:\n",
    "            mesh_file = input_dir / scene / 'area_1_occlusion' / 'per_view_gs_mesh.json'\n",
    "            if mesh_file.exists():\n",
    "                with open(mesh_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                iter_key = MESH_ITERATION if MESH_ITERATION in data else ITERATION\n",
    "                \n",
    "                if iter_key in data:\n",
    "                    metric_data = data[iter_key][metric_key]\n",
    "                    if isinstance(metric_data, dict):\n",
    "                        values = [v for v in metric_data.values() if v != -1.0]\n",
    "                        scene_mean = np.mean(values)\n",
    "                    else:\n",
    "                        scene_mean = metric_data\n",
    "                    \n",
    "                    mesh_values_all_scenes.append(scene_mean)\n",
    "                    print(f\"  {scene} - Pure Mesh: {scene_mean:.4f}\")\n",
    "        \n",
    "        mesh_mean = None\n",
    "        mesh_stderr = None\n",
    "        if mesh_values_all_scenes:\n",
    "            mesh_mean = np.mean(mesh_values_all_scenes)\n",
    "            mesh_std = np.std(mesh_values_all_scenes)\n",
    "            mesh_stderr = mesh_std / np.sqrt(len(mesh_values_all_scenes))\n",
    "            print(f\"Pure Mesh Average - {metric_key}: mean={mesh_mean:.4f}, std={mesh_std:.4f}, n={len(mesh_values_all_scenes)}\")\n",
    "        \n",
    "        # 2. Process each renderer\n",
    "        for renderer in renderers:\n",
    "            renderer_name = renderer['name']\n",
    "            is_games = renderer['is_games']\n",
    "            \n",
    "            xs = []\n",
    "            ys = []\n",
    "            errs = []\n",
    "            \n",
    "           # [NOTE] Our x=0 is mesh background, whereas GaMeS is blank\n",
    "            if mesh_mean is not None:\n",
    "                xs.append(0)\n",
    "                if is_games: #GaMeS results do not include pure mesh point\n",
    "                    ys.append( 1 if metric_key=='LPIPS' else 0 )\n",
    "                    errs.append(0)\n",
    "                else: #our DTGS/TGS results include pure mesh point\n",
    "                    ys.append(mesh_mean)\n",
    "                    errs.append(mesh_stderr)\n",
    "            \n",
    "            print(f\"\\nProcessing {renderer['label']}:\")\n",
    "            \n",
    "            for budget in budgets:\n",
    "                # Collect values across all scenes for this budget\n",
    "                budget_values_all_scenes = []\n",
    "                \n",
    "                for scene in SCENE_NAME_LIST:\n",
    "                    # Determine the correct file path\n",
    "                    if is_games:\n",
    "                        scene_dir = games_dir / scene\n",
    "                    else:\n",
    "                        scene_dir = input_dir / scene\n",
    "                    \n",
    "                    if renderer_name == 'dtgs' or renderer_name == 'games':\n",
    "                        policy_file = scene_dir / f'{POLICY}_{budget}_occlusion' / 'per_view_gs_mesh.json'\n",
    "                    else:\n",
    "                        policy_file = scene_dir / f'{POLICY}_{budget}_no_occlusion' / 'per_view_gs_mesh.json'\n",
    "                    \n",
    "                    if policy_file.exists():\n",
    "                        with open(policy_file, 'r') as f:\n",
    "                            data = json.load(f)\n",
    "                        \n",
    "                        if ITERATION in data:\n",
    "                            metric_data = data[ITERATION][metric_key]\n",
    "                            if isinstance(metric_data, dict):\n",
    "                                values = [v for v in metric_data.values() if v != -1.0]\n",
    "                                scene_mean = np.mean(values)\n",
    "                            else:\n",
    "                                scene_mean = metric_data\n",
    "                            \n",
    "                            budget_values_all_scenes.append(scene_mean)\n",
    "                            print(f\"  {scene} @ {budget}: {scene_mean:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"  {scene} @ {budget}: File not found\")\n",
    "                \n",
    "                # Compute average across scenes\n",
    "                if budget_values_all_scenes:\n",
    "                    mean_val = np.mean(budget_values_all_scenes)\n",
    "                    std_val = np.std(budget_values_all_scenes)\n",
    "                    stderr = std_val / np.sqrt(len(budget_values_all_scenes))\n",
    "                    \n",
    "                    xs.append(budget)\n",
    "                    ys.append(mean_val)\n",
    "                    errs.append(stderr)\n",
    "                    \n",
    "                    print(f\"  Budget {budget} Average: mean={mean_val:.4f}, std={std_val:.4f}, n={len(budget_values_all_scenes)}\")\n",
    "            \n",
    "            # Plot this renderer\n",
    "            if xs:\n",
    "                print(f\"  Plotting {len(xs)} points for {renderer['label']}\")\n",
    "                ax.errorbar(xs, ys, yerr=errs,\n",
    "                           marker=renderer['marker'], markersize=8, linewidth=2.5,\n",
    "                           capsize=err_capsize, capthick=err_capthick,\n",
    "                           color=renderer['color'], label=renderer['label'], zorder=2)\n",
    "            else:\n",
    "                print(f\"  No data to plot for {renderer['label']}!\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Bit Budget (\\#Gaussians)', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        \n",
    "        # Format x-axis to show values in K (thousands)\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K' if x > 0 else '0'))\n",
    "        \n",
    "        if metric_key == 'SSIM':\n",
    "            ax.set_ylim(top=1.01)\n",
    "        \n",
    "        \n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        base_name = f'{metric_key}_renderer_comp_average'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\nSaved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Run averaged comparison\n",
    "plot_renderer_comp_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125dcc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_renderer_comp_bar():\n",
    "    \"\"\"\n",
    "    Bar plot comparing renderers across scenes.\n",
    "    \n",
    "    For each metric (PSNR/SSIM/LPIPS):\n",
    "    - x-axis: bar groups for each scene + overall average\n",
    "    - Each group has bars for different renderers (DTGS, TGS, GaMeS)\n",
    "    - y-axis: quality in PSNR/SSIM/LPIPS\n",
    "    \"\"\"\n",
    "    ITERATION = 'ours_15000'\n",
    "    MESH_ITERATION = 'ours_1'\n",
    "    POLICY = 'uniform'\n",
    "    BUDGET = 640000  # Using highest budget for comparison\n",
    "    \n",
    "    input_dir = Path('./data')\n",
    "    games_dir = Path('./data/games_results')\n",
    "    output_dir = Path('./plots') / 'renderer_comp_bar'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define renderers\n",
    "    renderers = [\n",
    "        {'name': 'dtgs', 'label': 'DTGS', 'color': color_palette[0], 'is_games': False},\n",
    "        # {'name': 'tgs', 'label': 'TGS', 'color': color_palette[1], 'is_games': False},\n",
    "        {'name': 'games', 'label': 'GaMeS', 'color': color_palette[2], 'is_games': True},\n",
    "    ]\n",
    "    \n",
    "    metrics = {\n",
    "        'PSNR': {'ylabel': 'PSNR (dB)', 'title': 'PSNR'},\n",
    "        'SSIM': {'ylabel': 'SSIM', 'title': 'SSIM'},\n",
    "        'LPIPS': {'ylabel': 'LPIPS', 'title': 'LPIPS'},\n",
    "    }\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in metrics.items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Bar Chart for {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # x-axis labels: scene names + \"Average\"\n",
    "        x_labels = [scene.replace('-dw50', '') for scene in SCENE_NAME_LIST] + ['Average']\n",
    "        n_groups = len(x_labels)\n",
    "        n_renderers = len(renderers)\n",
    "        \n",
    "        # Bar positions\n",
    "        x_pos = np.arange(n_groups) * (n_renderers * bar_width + bar_space)\n",
    "        \n",
    "        # Collect data for each renderer\n",
    "        for renderer_idx, renderer in enumerate(renderers):\n",
    "            renderer_name = renderer['name']\n",
    "            is_games = renderer['is_games']\n",
    "            \n",
    "            group_values = []  # Values for each scene + average\n",
    "            \n",
    "            # Collect values for each scene\n",
    "            scene_values = []\n",
    "            \n",
    "            for scene in SCENE_NAME_LIST:\n",
    "                # Determine file path\n",
    "                if is_games:\n",
    "                    scene_dir = games_dir / scene\n",
    "                else:\n",
    "                    scene_dir = input_dir / scene\n",
    "                \n",
    "                if renderer_name == 'dtgs' or renderer_name == 'games':\n",
    "                    policy_file = scene_dir / f'{POLICY}_{BUDGET}_occlusion' / 'per_view_gs_mesh.json'\n",
    "                elif renderer_name == 'tgs':\n",
    "                    policy_file = scene_dir / f'{POLICY}_{BUDGET}_no_occlusion' / 'per_view_gs_mesh.json'\n",
    "                \n",
    "                if policy_file.exists():\n",
    "                    with open(policy_file, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    if ITERATION in data:\n",
    "                        metric_data = data[ITERATION][metric_key]\n",
    "                        if isinstance(metric_data, dict):\n",
    "                            values = [v for v in metric_data.values() if v != -1.0]\n",
    "                            scene_mean = np.mean(values)\n",
    "                        else:\n",
    "                            scene_mean = metric_data\n",
    "                        \n",
    "                        group_values.append(scene_mean)\n",
    "                        scene_values.append(scene_mean)\n",
    "                        print(f\"  {scene} - {renderer['label']}: mean={scene_mean:.4f}\")\n",
    "                    else:\n",
    "                        group_values.append(0)\n",
    "                else:\n",
    "                    print(f\"  {scene} - {renderer['label']}: File not found\")\n",
    "                    group_values.append(0)\n",
    "            \n",
    "            # Add overall average\n",
    "            if scene_values:\n",
    "                overall_mean = np.mean(scene_values)\n",
    "                group_values.append(overall_mean)\n",
    "                print(f\"  Overall - {renderer['label']}: mean={overall_mean:.4f}\")\n",
    "            else:\n",
    "                group_values.append(0)\n",
    "            \n",
    "            # Plot bars\n",
    "            offset = renderer_idx * (bar_width + bar_btw_space)\n",
    "            ax.bar(x_pos + offset, group_values, bar_width,\n",
    "                   label=renderer['label'], color=renderer['color'])\n",
    "        \n",
    "        # Formatting\n",
    "        # ax.set_xlabel('Scene', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        ax.set_xticks(x_pos + (n_renderers - 1) * (bar_width + bar_btw_space) / 2)\n",
    "        ax.set_xticklabels(x_labels, fontsize=16, rotation=30, ha='right')\n",
    "        ax.legend(loc='lower right', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        if metric_key == 'SSIM':\n",
    "            ax.set_ylim(top=1.01)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        # Save\n",
    "        base_name = f'{metric_key}_renderer_comp_bar_budget{BUDGET//1000}K'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\nSaved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Run the bar plot\n",
    "plot_renderer_comp_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca6a648",
   "metadata": {},
   "source": [
    "# Streaming Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79b497",
   "metadata": {},
   "source": [
    "## Parsers and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ae9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_metric_log(log_path, metric_type='psnr'):\n",
    "    \"\"\"\n",
    "    Parse PSNR or SSIM log file.\n",
    "    Returns: dict with frame_id -> metric_value\n",
    "    \n",
    "    Args:\n",
    "        log_path: Path to log file\n",
    "        metric_type: 'psnr' or 'ssim' to determine which field to extract\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    if not log_path.exists():\n",
    "        return metrics\n",
    "    \n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                # Extract frame_id from \"n:X\" format\n",
    "                frame_str = parts[0]\n",
    "                if frame_str.startswith('n:'):\n",
    "                    frame_id = int(frame_str.split(':')[1])\n",
    "                    \n",
    "                    # Look for the appropriate metric field\n",
    "                    if metric_type == 'psnr':\n",
    "                        search_key = 'psnr_avg:'\n",
    "                    elif metric_type == 'ssim':\n",
    "                        search_key = 'All:'  # SSIM uses \"All:\" for the overall value\n",
    "                    \n",
    "                    for part in parts:\n",
    "                        if part.startswith(search_key):\n",
    "                            metric_value = float(part.split(':')[1])\n",
    "                            metrics[frame_id] = metric_value\n",
    "                            break\n",
    "    return metrics\n",
    "\n",
    "def parse_vmaf_xml(xml_path, metric_type='vmaf'):\n",
    "    \"\"\"Parse VMAF XML file and return dict with frame data\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        frame_data = {}\n",
    "        for frame in root.findall('.//frame'):\n",
    "            frame_num = int(frame.get('frameNum'))\n",
    "            vmaf_score = float(frame.get('vmaf'))\n",
    "            frame_data[frame_num] = vmaf_score\n",
    "        \n",
    "        return frame_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================= Streaming Config ============================= #\n",
    "# Single source of truth for streaming experiments\n",
    "\n",
    "STREAMING_CONFIG = {\n",
    "    'scene': 'bicycle-dw50',\n",
    "    'policy': 'distortion',\n",
    "    'budget': 640000,\n",
    "    'iteration': 'ours_15000',\n",
    "    'streaming_settings': 'streaming_0',\n",
    "    \n",
    "    # Tile configurations\n",
    "    'tile_configs': [\n",
    "        {'n_tile': 1, 'label': '1', 'marker': 'o', 'color': color_palette[0]},\n",
    "        \n",
    "        {'n_tile': 4, 'label': '4', 'marker': 's', 'color': color_palette[1]},\n",
    "        {'n_tile': 16, 'label': '16', 'marker': '^', 'color': color_palette[2]},\n",
    "        # {'n_tile': 2, 'label': 'Adaptive-16', 'marker': '^', 'color': color_palette[2]},\n",
    "        # {'n_tile': 8, 'label': 'Adaptive-16', 'marker': '^', 'color': color_palette[2]},\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    # User traces\n",
    "    'user_traces': ['user1_bicycle', 'user2_bicycle', 'user3_bicycle'],\n",
    "    \n",
    "    # Network traces\n",
    "    'network_traces': [\n",
    "        'trace1_static_high',\n",
    "        'trace2_static_low',\n",
    "        'trace3_fluctuation_high',\n",
    "        'trace4_fluctuation_low'\n",
    "    ],\n",
    "    \n",
    "    # Metrics\n",
    "    'metrics': {\n",
    "        'PSNR': {'file': 'psnr.log', 'ylabel': 'PSNR (dB)', 'parser': parse_metric_log},\n",
    "        'SSIM': {'file': 'ssim.log', 'ylabel': 'SSIM', 'parser': parse_metric_log},\n",
    "        'VMAF': {'file': 'vmaf.csv', 'ylabel': 'VMAF', 'parser': parse_vmaf_xml},\n",
    "        # don't mind the .csv, the content is in XML format\n",
    "    },\n",
    "    \n",
    "    # Paths\n",
    "    'input_base': Path('./data/streaming'),\n",
    "    'output_base': Path('./plots/streaming')\n",
    "}\n",
    "\n",
    "# ============================================================================ #\n",
    "\n",
    "\n",
    "def get_streaming_path(scene, policy, budget, iteration, n_tile, user_trace, network_trace, streaming_settings, iter_name):\n",
    "    \"\"\"\n",
    "    Construct streaming data path following the naming convention.\n",
    "    \n",
    "    Returns: Path object\n",
    "    \"\"\"\n",
    "    return (STREAMING_CONFIG['input_base'] / scene / \n",
    "            f'{policy}_{budget}_occlusion' /\n",
    "            f'iteration_{iteration.split(\"_\")[1]}' /\n",
    "            f'ply-adaptive-{n_tile}' / \n",
    "            user_trace / \n",
    "            network_trace / \n",
    "            streaming_settings / \n",
    "            iter_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d6bfe",
   "metadata": {},
   "source": [
    "## Tile Number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config same as before\n",
    "**scene is bicycle-dw50**\n",
    "\n",
    "\n",
    "\n",
    "path name rules:\n",
    "```\n",
    "\"data/streaming/${SCENE_NAME}/${POLICY}_${BUDGET}_${OCCLUSION_FLAG}/iteration_${ITERATION}/\n",
    "- ply-adaptive-${N_TILE_DIM}/\n",
    "    - ${USER_TRACE_NAME}/\n",
    "        - ${NETWORK_TRACE_NAME}/\n",
    "            - ${STREAMING_SETTINGS_NAME}\"\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f2ddcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Generating Individual Plots (12 plots per metric)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Plotting Individual PSNR\n",
      "============================================================\n",
      "\n",
      "user1_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=40.15\n",
      "  4: 900 frames, avg=39.08\n",
      "  16: 900 frames, avg=39.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user1_bicycle_trace1_static_high\n",
      "\n",
      "user1_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=6.95\n",
      "  4: 900 frames, avg=8.50\n",
      "  16: 900 frames, avg=10.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user1_bicycle_trace2_static_low\n",
      "\n",
      "user1_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=42.54\n",
      "  4: 900 frames, avg=42.86\n",
      "  16: 900 frames, avg=43.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user1_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user1_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=18.16\n",
      "  4: 900 frames, avg=27.84\n",
      "  16: 900 frames, avg=29.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user1_bicycle_trace4_fluctuation_low\n",
      "\n",
      "user2_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=37.12\n",
      "  4: 900 frames, avg=39.08\n",
      "  16: 900 frames, avg=39.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user2_bicycle_trace1_static_high\n",
      "\n",
      "user2_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=7.58\n",
      "  4: 900 frames, avg=8.90\n",
      "  16: 900 frames, avg=18.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user2_bicycle_trace2_static_low\n",
      "\n",
      "user2_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=39.27\n",
      "  4: 900 frames, avg=41.80\n",
      "  16: 900 frames, avg=43.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user2_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user2_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=18.47\n",
      "  4: 900 frames, avg=37.18\n",
      "  16: 900 frames, avg=38.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user2_bicycle_trace4_fluctuation_low\n",
      "\n",
      "user3_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=40.60\n",
      "  4: 900 frames, avg=40.61\n",
      "  16: 900 frames, avg=41.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user3_bicycle_trace1_static_high\n",
      "\n",
      "user3_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=6.99\n",
      "  4: 900 frames, avg=8.12\n",
      "  16: 900 frames, avg=8.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user3_bicycle_trace2_static_low\n",
      "\n",
      "user3_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=42.88\n",
      "  4: 900 frames, avg=44.64\n",
      "  16: 900 frames, avg=46.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user3_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user3_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=17.13\n",
      "  4: 900 frames, avg=25.94\n",
      "  16: 900 frames, avg=29.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: PSNR_user3_bicycle_trace4_fluctuation_low\n",
      "\n",
      "============================================================\n",
      "Plotting Individual SSIM\n",
      "============================================================\n",
      "\n",
      "user1_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=0.90\n",
      "  4: 900 frames, avg=0.91\n",
      "  16: 900 frames, avg=0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user1_bicycle_trace1_static_high\n",
      "\n",
      "user1_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=0.64\n",
      "  4: 900 frames, avg=0.69\n",
      "  16: 900 frames, avg=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user1_bicycle_trace2_static_low\n",
      "\n",
      "user1_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=0.91\n",
      "  4: 900 frames, avg=0.94\n",
      "  16: 900 frames, avg=0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user1_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user1_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=0.77\n",
      "  4: 900 frames, avg=0.87\n",
      "  16: 900 frames, avg=0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user1_bicycle_trace4_fluctuation_low\n",
      "\n",
      "user2_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=0.92\n",
      "  4: 900 frames, avg=0.94\n",
      "  16: 900 frames, avg=0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user2_bicycle_trace1_static_high\n",
      "\n",
      "user2_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=0.69\n",
      "  4: 900 frames, avg=0.73\n",
      "  16: 900 frames, avg=0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user2_bicycle_trace2_static_low\n",
      "\n",
      "user2_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=0.93\n",
      "  4: 900 frames, avg=0.96\n",
      "  16: 900 frames, avg=0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user2_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user2_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=0.82\n",
      "  4: 900 frames, avg=0.93\n",
      "  16: 900 frames, avg=0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user2_bicycle_trace4_fluctuation_low\n",
      "\n",
      "user3_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=0.92\n",
      "  4: 900 frames, avg=0.94\n",
      "  16: 900 frames, avg=0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user3_bicycle_trace1_static_high\n",
      "\n",
      "user3_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=0.64\n",
      "  4: 900 frames, avg=0.68\n",
      "  16: 900 frames, avg=0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user3_bicycle_trace2_static_low\n",
      "\n",
      "user3_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=0.93\n",
      "  4: 900 frames, avg=0.96\n",
      "  16: 900 frames, avg=0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user3_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user3_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=0.78\n",
      "  4: 900 frames, avg=0.88\n",
      "  16: 900 frames, avg=0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: SSIM_user3_bicycle_trace4_fluctuation_low\n",
      "\n",
      "============================================================\n",
      "Plotting Individual VMAF\n",
      "============================================================\n",
      "\n",
      "user1_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=73.30\n",
      "  4: 900 frames, avg=76.11\n",
      "  16: 900 frames, avg=78.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user1_bicycle_trace1_static_high\n",
      "\n",
      "user1_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=3.97\n",
      "  4: 900 frames, avg=23.95\n",
      "  16: 900 frames, avg=31.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user1_bicycle_trace2_static_low\n",
      "\n",
      "user1_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=77.54\n",
      "  4: 900 frames, avg=81.13\n",
      "  16: 900 frames, avg=82.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user1_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user1_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=33.17\n",
      "  4: 900 frames, avg=64.83\n",
      "  16: 900 frames, avg=68.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user1_bicycle_trace4_fluctuation_low\n",
      "\n",
      "user2_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=73.47\n",
      "  4: 900 frames, avg=83.99\n",
      "  16: 900 frames, avg=84.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user2_bicycle_trace1_static_high\n",
      "\n",
      "user2_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=0.90\n",
      "  4: 900 frames, avg=16.21\n",
      "  16: 900 frames, avg=39.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user2_bicycle_trace2_static_low\n",
      "\n",
      "user2_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=77.93\n",
      "  4: 900 frames, avg=90.85\n",
      "  16: 900 frames, avg=93.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user2_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user2_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=29.99\n",
      "  4: 900 frames, avg=79.80\n",
      "  16: 900 frames, avg=83.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user2_bicycle_trace4_fluctuation_low\n",
      "\n",
      "user3_bicycle - trace1_static_high\n",
      "  1: 900 frames, avg=72.93\n",
      "  4: 900 frames, avg=83.08\n",
      "  16: 900 frames, avg=87.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user3_bicycle_trace1_static_high\n",
      "\n",
      "user3_bicycle - trace2_static_low\n",
      "  1: 900 frames, avg=4.02\n",
      "  4: 900 frames, avg=21.03\n",
      "  16: 900 frames, avg=19.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user3_bicycle_trace2_static_low\n",
      "\n",
      "user3_bicycle - trace3_fluctuation_high\n",
      "  1: 900 frames, avg=77.37\n",
      "  4: 900 frames, avg=91.98\n",
      "  16: 900 frames, avg=93.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user3_bicycle_trace3_fluctuation_high\n",
      "\n",
      "user3_bicycle - trace4_fluctuation_low\n",
      "  1: 900 frames, avg=24.29\n",
      "  4: 900 frames, avg=58.86\n",
      "  16: 900 frames, avg=65.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: VMAF_user3_bicycle_trace4_fluctuation_low\n"
     ]
    }
   ],
   "source": [
    "def plot_tiling_individual():\n",
    "    \"\"\"\n",
    "    Plot quality for each individual user-network trace combination.\n",
    "    Creates 12 separate plots (3 users  4 network traces).\n",
    "    \n",
    "    For each plot:\n",
    "    - x-axis: time (seconds)\n",
    "    - y-axis: quality (PSNR/SSIM/VMAF)\n",
    "    - hue: different n_tile configurations (1, 4, 16)\n",
    "    \"\"\"\n",
    "    \n",
    "    cfg = STREAMING_CONFIG\n",
    "    output_dir = cfg['output_base'] / 'line_plots' / 'tiling_individual' / cfg['scene']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    FPS = 30.0  # Frames per second\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in cfg['metrics'].items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Individual {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # For each user-network combination\n",
    "        for user_trace in cfg['user_traces']:\n",
    "            for network_trace in cfg['network_traces']:\n",
    "                fig, ax = plt.subplots(figsize=(9.6,4.8))\n",
    "                \n",
    "                print(f\"\\n{user_trace} - {network_trace}\")\n",
    "                \n",
    "                # Plot each tile configuration\n",
    "                for tile_cfg in cfg['tile_configs']:\n",
    "                    n_tile = tile_cfg['n_tile']\n",
    "                    \n",
    "                    data_path = get_streaming_path(\n",
    "                        cfg['scene'], cfg['policy'], cfg['budget'], \n",
    "                        cfg['iteration'], n_tile, user_trace, \n",
    "                        network_trace, cfg['streaming_settings'], \n",
    "                        cfg['iteration']\n",
    "                    )\n",
    "                    \n",
    "                    metric_file = data_path / metric_info['file']\n",
    "                    \n",
    "                    if metric_file.exists():\n",
    "                        data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                        \n",
    "                        if data:\n",
    "                            frames = sorted(data.keys())\n",
    "                            values = [data[f] for f in frames]\n",
    "                            \n",
    "                            # Convert frames to time (seconds)\n",
    "                            times = [frame / FPS for frame in frames]\n",
    "                            \n",
    "                            ax.plot(times, values,\n",
    "                                   linewidth=2, color=tile_cfg['color'],\n",
    "                                   label=tile_cfg['label'], zorder=2)\n",
    "                            \n",
    "                            print(f\"  {tile_cfg['label']}: {len(frames)} frames, \"\n",
    "                                  f\"avg={np.mean(values):.2f}\")\n",
    "                        else:\n",
    "                            print(f\"  {tile_cfg['label']}: No data parsed\")\n",
    "                    else:\n",
    "                        print(f\"  {tile_cfg['label']}: File not found\")\n",
    "                \n",
    "                # Formatting\n",
    "                ax.set_xlabel('Time (seconds)', fontsize=20)\n",
    "                ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "                ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "                ax.tick_params(labelsize=18)\n",
    "                ax.set_axisbelow(True)\n",
    "                \n",
    "                # Set consistent axis limits\n",
    "                ax.set_xlim(left=-0.5, right=30.5)\n",
    "                if metric_key == 'VMAF':\n",
    "                    ax.set_ylim(bottom=-1, top=101)\n",
    "                elif metric_key == 'SSIM':\n",
    "                    ax.set_ylim(top=1.01)\n",
    "                elif metric_key == 'PSNR':\n",
    "                    ax.set_ylim(bottom=0)\n",
    "                \n",
    "                fig.set_constrained_layout(True)\n",
    "                \n",
    "                # Save\n",
    "                base_name = f'{metric_key}_{user_trace}_{network_trace}'\n",
    "                plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "                plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "                print(f\"  Saved: {base_name}\")\n",
    "                \n",
    "                plt.close()\n",
    "\n",
    "# Run both plotting functions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Individual Plots (12 plots per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_tiling_individual()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_tiling_quality_overall():\n",
    "    \"\"\"\n",
    "    Plot overall average quality across ALL user traces and network traces.\n",
    "    Shows mean lines only (no markers or error bands).\n",
    "    \n",
    "    Averages over: 3 users  4 network traces = 12 combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    cfg = STREAMING_CONFIG\n",
    "    output_dir = cfg['output_base'] / 'line_plots' / 'tiling_average' / cfg['scene']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    FPS = 30.0  # Frames per second\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in cfg['metrics'].items():\n",
    "        fig, ax = plt.subplots(figsize=(9.6,4.8))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Overall Average {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Plot each tile configuration averaged across ALL combinations\n",
    "        for tile_cfg in cfg['tile_configs']:\n",
    "            n_tile = tile_cfg['n_tile']\n",
    "            \n",
    "            # Collect data from all user-network combinations\n",
    "            all_combinations_data = []\n",
    "            \n",
    "            for user_trace in cfg['user_traces']:\n",
    "                for network_trace in cfg['network_traces']:\n",
    "                    data_path = get_streaming_path(\n",
    "                        cfg['scene'], cfg['policy'], cfg['budget'], \n",
    "                        cfg['iteration'], n_tile, user_trace, \n",
    "                        network_trace, cfg['streaming_settings'], \n",
    "                        cfg['iteration']\n",
    "                    )\n",
    "                    \n",
    "                    metric_file = data_path / metric_info['file']\n",
    "                    \n",
    "                    if metric_file.exists():\n",
    "                        data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                        if data:\n",
    "                            all_combinations_data.append(data)\n",
    "                            print(f\"  Loaded: {user_trace}/{network_trace} - {len(data)} frames\")\n",
    "            \n",
    "            if all_combinations_data:\n",
    "                # Find common frames across all combinations\n",
    "                all_frames = set(all_combinations_data[0].keys())\n",
    "                for data in all_combinations_data[1:]:\n",
    "                    all_frames &= set(data.keys())\n",
    "                all_frames = sorted(all_frames)\n",
    "                \n",
    "                # Convert frames to time (seconds)\n",
    "                all_times = [frame / FPS for frame in all_frames]\n",
    "                \n",
    "                means = []\n",
    "                \n",
    "                for frame in all_frames:\n",
    "                    frame_values = [data[frame] for data in all_combinations_data if frame in data]\n",
    "                    if frame_values:\n",
    "                        means.append(np.mean(frame_values))\n",
    "                \n",
    "                means = np.array(means)\n",
    "                \n",
    "                # Plot mean line only (no markers)\n",
    "                ax.plot(all_times, means,\n",
    "                       linewidth=2, color=tile_cfg['color'],\n",
    "                       label=tile_cfg['label'], zorder=2)\n",
    "                \n",
    "                print(f\"\\n  {tile_cfg['label']} overall average:\")\n",
    "                print(f\"    Combinations: {len(all_combinations_data)}\")\n",
    "                print(f\"    Frames: {len(all_frames)}\")\n",
    "                print(f\"    Mean: {np.mean(means):.2f}\")\n",
    "            else:\n",
    "                print(f\"  No data found for {tile_cfg['label']}\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Time (seconds)', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        \n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        # ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        ax.set_xlim(left=-0.5, right=30.5)\n",
    "        if metric_key == 'VMAF':\n",
    "            ax.set_ylim(bottom=-1, top=101)\n",
    "        elif metric_key == 'SSIM':\n",
    "            ax.set_ylim( top=1.01)\n",
    "        elif metric_key == 'PSNR':\n",
    "            ax.set_ylim( bottom=0)\n",
    "            \n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        # Save\n",
    "        base_name = f'{metric_key}_overall_average_budget{cfg[\"budget\"]//1000}K'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\n  Saved: {base_name}.png and .eps\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Overall Average Plot (1 plot per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_tiling_quality_overall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32332e71",
   "metadata": {},
   "source": [
    "## Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21485080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_streaming_bar():\n",
    "    \"\"\"\n",
    "    Bar plot showing average quality for each network trace + overall average.\n",
    "    \n",
    "    For each metric (PSNR/SSIM/VMAF):\n",
    "    - x-axis: 5 bar groups (4 network traces + 1 overall average)\n",
    "    - Each group has bars for different n_tile configs (1, 4, 16)\n",
    "    - Bars show average across 3 users with error bars\n",
    "    \"\"\"\n",
    "    \n",
    "    cfg = STREAMING_CONFIG\n",
    "    output_dir = cfg['output_base'] / 'bar_plots' / cfg['scene']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in cfg['metrics'].items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Bar Chart for {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Prepare data structure with shorthand labels\n",
    "        trace_label_map = {\n",
    "            'trace1_static_high': 'SH',\n",
    "            'trace2_static_low': 'SL',\n",
    "            'trace3_fluctuation_high': 'FH',\n",
    "            'trace4_fluctuation_low': 'FL'\n",
    "        }\n",
    "        x_labels = [trace_label_map[trace] for trace in cfg['network_traces']] + ['Overall']\n",
    "        n_groups = len(x_labels)\n",
    "        n_tiles = len(cfg['tile_configs'])\n",
    "        \n",
    "        # Bar positions using global config\n",
    "        x_pos = np.arange(n_groups) * (n_tiles * bar_width + bar_space)\n",
    "        \n",
    "        # Collect data for each tile config\n",
    "        for tile_idx, tile_cfg in enumerate(cfg['tile_configs']):\n",
    "            n_tile = tile_cfg['n_tile']\n",
    "            \n",
    "            group_means = []\n",
    "            group_stds = []\n",
    "            \n",
    "            # Process each network trace\n",
    "            for network_trace in cfg['network_traces']:\n",
    "                trace_values = []\n",
    "                \n",
    "                for user_trace in cfg['user_traces']:\n",
    "                    data_path = get_streaming_path(\n",
    "                        cfg['scene'], cfg['policy'], cfg['budget'],\n",
    "                        cfg['iteration'], n_tile, user_trace,\n",
    "                        network_trace, cfg['streaming_settings'],\n",
    "                        cfg['iteration']\n",
    "                    )\n",
    "                    \n",
    "                    metric_file = data_path / metric_info['file']\n",
    "                    \n",
    "                    if metric_file.exists():\n",
    "                        data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                        if data:\n",
    "                            user_avg = np.mean(list(data.values()))\n",
    "                            trace_values.append(user_avg)\n",
    "                \n",
    "                if trace_values:\n",
    "                    group_means.append(np.mean(trace_values))\n",
    "                    group_stds.append(np.std(trace_values) / np.sqrt(len(trace_values)))\n",
    "                    print(f\"  {network_trace} - {tile_cfg['label']}: mean={np.mean(trace_values):.2f}\")\n",
    "                else:\n",
    "                    group_means.append(0)\n",
    "                    group_stds.append(0)\n",
    "            \n",
    "            # Overall average\n",
    "            overall_values = []\n",
    "            for user_trace in cfg['user_traces']:\n",
    "                for network_trace in cfg['network_traces']:\n",
    "                    data_path = get_streaming_path(\n",
    "                        cfg['scene'], cfg['policy'], cfg['budget'],\n",
    "                        cfg['iteration'], n_tile, user_trace,\n",
    "                        network_trace, cfg['streaming_settings'],\n",
    "                        cfg['iteration']\n",
    "                    )\n",
    "                    \n",
    "                    metric_file = data_path / metric_info['file']\n",
    "                    \n",
    "                    if metric_file.exists():\n",
    "                        data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                        if data:\n",
    "                            overall_values.append(np.mean(list(data.values())))\n",
    "            \n",
    "            if overall_values:\n",
    "                group_means.append(np.mean(overall_values))\n",
    "                group_stds.append(np.std(overall_values) / np.sqrt(len(overall_values)))\n",
    "            else:\n",
    "                group_means.append(0)\n",
    "                group_stds.append(0)\n",
    "            \n",
    "            # Plot bars using global bar_width and bar_btw_space\n",
    "            offset = tile_idx * (bar_width + bar_btw_space)\n",
    "            ax.bar(x_pos + offset, group_means, bar_width,\n",
    "                   yerr=group_stds, capsize=err_capsize,\n",
    "                   label=tile_cfg['label'], color=tile_cfg['color'],\n",
    "                   error_kw={'elinewidth': err_lw, 'capthick': err_capthick})\n",
    "        \n",
    "        # Formatting\n",
    "        \n",
    "        \n",
    "        if metric_key == 'VMAF':\n",
    "            ax.set_ylim( top=100)\n",
    "        \n",
    "        ax.set_xlabel('Network Trace', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        ax.set_xticks(x_pos + (n_tiles - 1) * (bar_width + bar_btw_space) / 2)\n",
    "        ax.set_xticklabels(x_labels, fontsize=16)\n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=16)\n",
    "        ax.tick_params(labelsize=16)\n",
    "        # ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        base_name = f'{metric_key}_bar_network_traces_budget{cfg[\"budget\"]//1000}K'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\n  Saved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Bar Plots (1 plot per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_streaming_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3184273c",
   "metadata": {},
   "source": [
    "## Network Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_traces():\n",
    "    \"\"\"\n",
    "    Plot network throughput traces over time.\n",
    "    \n",
    "    Shows throughput (Mbps) vs time (seconds) for different network conditions.\n",
    "    Legend shows: Label (mean  95% CI Mbps)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    trace_dir = Path('./data/net_trace/network_trace')\n",
    "    output_dir = Path('./plots') / 'network_traces'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define network traces with configurations\n",
    "    traces = [\n",
    "        {'file': 'trace1_static_high.csv', 'stats': 'trace1_static_high_stats.txt', \n",
    "         'label': 'SH', 'color': color_palette[0]},\n",
    "        {'file': 'trace2_static_low.csv', 'stats': 'trace2_static_low_stats.txt',\n",
    "         'label': 'SL', 'color': color_palette[1]},\n",
    "        {'file': 'trace3_fluctuation_high.csv', 'stats': 'trace3_fluctuation_high_stats.txt',\n",
    "         'label': 'FH', 'color': color_palette[2]},\n",
    "        {'file': 'trace4_fluctuation_low.csv', 'stats': 'trace4_fluctuation_low_stats.txt',\n",
    "         'label': 'FL', 'color': color_palette[3]},\n",
    "    ]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(9.6, 4.8))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Plotting Network Throughput Traces\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Plot each trace\n",
    "    for trace in traces:\n",
    "        trace_path = trace_dir / trace['file']\n",
    "        stats_path = trace_dir / trace['stats']\n",
    "        \n",
    "        if not trace_path.exists():\n",
    "            print(f\"[WARN] File not found: {trace_path}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Read CSV (assumes headers \"time\" and \"throughput_kbps\")\n",
    "            df = pd.read_csv(trace_path)\n",
    "            \n",
    "            # Read statistics file\n",
    "            mean_kbps = None\n",
    "            std_kbps = None\n",
    "            \n",
    "            if stats_path.exists():\n",
    "                with open(stats_path, 'r') as f:\n",
    "                    for line in f:\n",
    "                        if line.startswith('Mean:'):\n",
    "                            mean_kbps = float(line.split(':')[1].strip())\n",
    "                        elif line.startswith('Std:'):\n",
    "                            std_kbps = float(line.split(':')[1].strip())\n",
    "            \n",
    "            # Convert to Mbps\n",
    "            throughput_mbps = df['throughput_kbps'] / 1000\n",
    "            \n",
    "            # Calculate 95% CI if stats available\n",
    "            if mean_kbps is not None and std_kbps is not None:\n",
    "                mean_mbps = mean_kbps / 1000\n",
    "                std_mbps = std_kbps / 1000\n",
    "                # 95% CI = 1.96 * std\n",
    "                ci_95 = 1.96 * std_mbps\n",
    "                label = f\"{trace['label']} ({mean_mbps:.1f}$\\\\pm${ci_95:.1f} Mbps)\"\n",
    "                \n",
    "                print(f\"  {trace['label']}: mean={mean_mbps:.2f} Mbps, \"\n",
    "                      f\"std={std_mbps:.2f} Mbps, 95% CI={ci_95:.2f} Mbps\")\n",
    "            else:\n",
    "                # Fallback: calculate from data\n",
    "                mean_mbps = throughput_mbps.mean()\n",
    "                std_mbps = throughput_mbps.std()\n",
    "                ci_95 = 1.96 * std_mbps\n",
    "                label = f\"{trace['label']} ({mean_mbps:.1f}$\\\\pm${ci_95:.1f} Mbps)\"\n",
    "                \n",
    "                print(f\"  {trace['label']}: mean={mean_mbps:.2f} Mbps (from data), \"\n",
    "                      f\"std={std_mbps:.2f} Mbps, 95% CI={ci_95:.2f} Mbps\")\n",
    "            \n",
    "            # Calculate latency statistics\n",
    "            if 'latency_ms' in df.columns:\n",
    "                mean_latency = df['latency_ms'].mean()\n",
    "                std_latency = df['latency_ms'].std()\n",
    "                print(f\"  {trace['label']} - Latency:\")\n",
    "                print(f\"    Mean: {mean_latency:.2f} ms\")\n",
    "                print(f\"    Std: {std_latency:.2f} ms\")\n",
    "            \n",
    "            \n",
    "            # Plot line\n",
    "            ax.plot(df['time'], throughput_mbps,\n",
    "                   linewidth=2, alpha=0.8,\n",
    "                   color=trace['color'], label=label, zorder=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to read {trace['file']}: {e}\")\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Time (sec)', fontsize=20)\n",
    "    ax.set_ylabel('Throughput (Mbps)', fontsize=20)\n",
    "    ax.legend(loc='best', ncol=2 ,framealpha=0.9, fontsize=16)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_ylim(top=420)\n",
    "    \n",
    "    fig.set_constrained_layout(True)\n",
    "    \n",
    "    # Save both formats\n",
    "    base_name = 'network_throughput_traces'\n",
    "    plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "    print(f\"\\nSaved: {base_name}.png and .eps\\n\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Run the plot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Network Trace Plot\")\n",
    "print(\"=\"*60)\n",
    "plot_network_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddfb25",
   "metadata": {},
   "source": [
    "## Concurrent Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_concurrent_streams_overall_tile16():\n",
    "    \"\"\"\n",
    "    Plot overall average quality across ALL user traces and network traces\n",
    "    for different concurrent stream settings.\n",
    "    \n",
    "    Fixed: n_tile = 16\n",
    "    Hue: streaming_settings (0, 3, 4) representing (16, 8, 4) concurrent streams\n",
    "    Averages over: 3 users  4 network traces = 12 combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    cfg = STREAMING_CONFIG\n",
    "    output_dir = cfg['output_base'] / 'line_plots' / 'concurrent_streams' / cfg['scene']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    FPS = 30.0  # Frames per second\n",
    "    \n",
    "    # Fixed tile configuration\n",
    "    N_TILE = 16\n",
    "    \n",
    "    # Define streaming settings with their configurations\n",
    "    streaming_configs = [\n",
    "        {'setting': 'streaming_0', 'label': '16', 'color': color_palette[0]},\n",
    "        {'setting': 'streaming_3', 'label': '8', 'color': color_palette[1]},\n",
    "        {'setting': 'streaming_4', 'label': '4', 'color': color_palette[2]},\n",
    "    ]\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in cfg['metrics'].items():\n",
    "        fig, ax = plt.subplots(figsize=(9.6, 4.8))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Concurrent Streams Average {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Plot each streaming configuration averaged across ALL combinations\n",
    "        for stream_cfg in streaming_configs:\n",
    "            streaming_setting = stream_cfg['setting']\n",
    "            \n",
    "            # Collect data from all user-network combinations\n",
    "            all_combinations_data = []\n",
    "            \n",
    "            for user_trace in cfg['user_traces']:\n",
    "                for network_trace in cfg['network_traces']:\n",
    "                    data_path = get_streaming_path(\n",
    "                        cfg['scene'], cfg['policy'], cfg['budget'], \n",
    "                        cfg['iteration'], N_TILE, user_trace, \n",
    "                        network_trace, streaming_setting, \n",
    "                        cfg['iteration']\n",
    "                    )\n",
    "                    \n",
    "                    metric_file = data_path / metric_info['file']\n",
    "                    \n",
    "                    if metric_file.exists():\n",
    "                        data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                        if data:\n",
    "                            all_combinations_data.append(data)\n",
    "                            print(f\"  Loaded: {user_trace}/{network_trace}/{streaming_setting} - {len(data)} frames\")\n",
    "                    else:\n",
    "                        print(f\"  [WARN] Not found: {user_trace}/{network_trace}/{streaming_setting}\")\n",
    "            \n",
    "            if all_combinations_data:\n",
    "                # Find common frames across all combinations\n",
    "                all_frames = set(all_combinations_data[0].keys())\n",
    "                for data in all_combinations_data[1:]:\n",
    "                    all_frames &= set(data.keys())\n",
    "                all_frames = sorted(all_frames)\n",
    "                \n",
    "                # Convert frames to time (seconds)\n",
    "                all_times = [frame / FPS for frame in all_frames]\n",
    "                \n",
    "                means = []\n",
    "                \n",
    "                for frame in all_frames:\n",
    "                    frame_values = [data[frame] for data in all_combinations_data if frame in data]\n",
    "                    if frame_values:\n",
    "                        means.append(np.mean(frame_values))\n",
    "                \n",
    "                means = np.array(means)\n",
    "                \n",
    "                # Plot mean line only (no markers)\n",
    "                ax.plot(all_times, means,\n",
    "                       linewidth=2, color=stream_cfg['color'],\n",
    "                       label=stream_cfg['label'], zorder=2)\n",
    "                \n",
    "                print(f\"\\n  {stream_cfg['label']} overall average:\")\n",
    "                print(f\"    Combinations: {len(all_combinations_data)}\")\n",
    "                print(f\"    Frames: {len(all_frames)}\")\n",
    "                print(f\"    Mean: {np.mean(means):.2f}\")\n",
    "            else:\n",
    "                print(f\"  [ERROR] No data found for {stream_cfg['label']}\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Time (seconds)', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        \n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        ax.set_xlim(left=-0.5, right=30.5)\n",
    "        if metric_key == 'VMAF':\n",
    "            ax.set_ylim(bottom=-1, top=101)\n",
    "        elif metric_key == 'SSIM':\n",
    "            ax.set_ylim(top=1.01)\n",
    "        elif metric_key == 'PSNR':\n",
    "            ax.set_ylim(bottom=0)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        # Save\n",
    "        base_name = f'{metric_key}_concurrent_streams_average_tile{N_TILE}'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\n  Saved: {base_name}.png and .eps\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "\n",
    "  \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Overall Average Plot (1 plot per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_concurrent_streams_overall_tile16()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f154174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_concurrent_streams_overall_by_tiles():\n",
    "    \"\"\"\n",
    "    Plot overall average quality across ALL user traces and network traces\n",
    "    for different concurrent stream settings.\n",
    "    \n",
    "    x-axis: number of tiles (1, 4, 16)\n",
    "    y-axis: quality (PSNR/SSIM/VMAF)\n",
    "    Hue: streaming_settings (0, 3, 4) representing (16, 8, 4) concurrent streams\n",
    "    Averages over: 3 users  4 network traces = 12 combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    cfg = STREAMING_CONFIG\n",
    "    output_dir = cfg['output_base'] / 'bar_plots' / 'concurrent_streams_tiles' / cfg['scene']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define streaming settings with their configurations\n",
    "    streaming_configs = [\n",
    "        {'setting': 'streaming_0', 'label': '16 streams', 'color': color_palette[0]},\n",
    "        {'setting': 'streaming_3', 'label': '8 streams', 'color': color_palette[1]},\n",
    "        {'setting': 'streaming_4', 'label': '4 streams', 'color': color_palette[2]},\n",
    "    ]\n",
    "    \n",
    "    # Tile configurations to test\n",
    "    tile_configs = [1, 4, 16]\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in cfg['metrics'].items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Concurrent Streams by Tiles - {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # x-axis labels\n",
    "        x_labels = [str(n) for n in tile_configs]\n",
    "        n_groups = len(x_labels)\n",
    "        n_streams = len(streaming_configs)\n",
    "        \n",
    "        # Bar positions\n",
    "        x_pos = np.arange(n_groups) * (n_streams * bar_width + bar_space)\n",
    "        \n",
    "        # Collect data for each streaming configuration\n",
    "        for stream_idx, stream_cfg in enumerate(streaming_configs):\n",
    "            streaming_setting = stream_cfg['setting']\n",
    "            \n",
    "            group_means = []\n",
    "            group_stds = []\n",
    "            \n",
    "            # For each tile configuration\n",
    "            for n_tile in tile_configs:\n",
    "                tile_values = []\n",
    "                \n",
    "                # Collect data from all user-network combinations\n",
    "                for user_trace in cfg['user_traces']:\n",
    "                    for network_trace in cfg['network_traces']:\n",
    "                        data_path = get_streaming_path(\n",
    "                            cfg['scene'], cfg['policy'], cfg['budget'],\n",
    "                            cfg['iteration'], n_tile, user_trace,\n",
    "                            network_trace, streaming_setting,\n",
    "                            cfg['iteration']\n",
    "                        )\n",
    "                        \n",
    "                        metric_file = data_path / metric_info['file']\n",
    "                        \n",
    "                        if metric_file.exists():\n",
    "                            data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                            if data:\n",
    "                                # Average over all frames for this combination\n",
    "                                combination_avg = np.mean(list(data.values()))\n",
    "                                tile_values.append(combination_avg)\n",
    "                        else:\n",
    "                            print(f\"  [WARN] Not found: tile{n_tile}/{user_trace}/{network_trace}/{streaming_setting}\")\n",
    "                \n",
    "                # Calculate mean and stderr for this tile configuration\n",
    "                if tile_values:\n",
    "                    mean_val = np.mean(tile_values)\n",
    "                    std_val = np.std(tile_values)\n",
    "                    stderr = std_val / np.sqrt(len(tile_values))\n",
    "                    \n",
    "                    group_means.append(mean_val)\n",
    "                    group_stds.append(stderr)\n",
    "                    \n",
    "                    print(f\"  Tile {n_tile} - {stream_cfg['label']}: \"\n",
    "                          f\"mean={mean_val:.2f}, std={std_val:.2f}, n={len(tile_values)}\")\n",
    "                else:\n",
    "                    group_means.append(0)\n",
    "                    group_stds.append(0)\n",
    "                    print(f\"  [ERROR] No data for tile {n_tile} - {stream_cfg['label']}\")\n",
    "            \n",
    "            # Plot bars\n",
    "            offset = stream_idx * (bar_width + bar_btw_space)\n",
    "            ax.bar(x_pos + offset, group_means, bar_width,\n",
    "                   yerr=group_stds, capsize=err_capsize,\n",
    "                   label=stream_cfg['label'], color=stream_cfg['color'],\n",
    "                   error_kw={'elinewidth': err_lw, 'capthick': err_capthick})\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Number of Tiles', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        ax.set_xticks(x_pos + (n_streams - 1) * (bar_width + bar_btw_space) / 2)\n",
    "        ax.set_xticklabels(x_labels, fontsize=18)\n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        # Set y-axis limits based on metric\n",
    "        if metric_key == 'VMAF':\n",
    "            ax.set_ylim(bottom=0, top=100)\n",
    "        elif metric_key == 'SSIM':\n",
    "            ax.set_ylim(top=1.01)\n",
    "        elif metric_key == 'PSNR':\n",
    "            ax.set_ylim(bottom=0)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        # Save\n",
    "        base_name = f'{metric_key}_concurrent_streams_by_tiles_budget{cfg[\"budget\"]//1000}K'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\n  Saved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Run the plot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Concurrent Streams by Tiles Plot (1 plot per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_concurrent_streams_overall_by_tiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced905c",
   "metadata": {},
   "source": [
    "## Allocation window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_allocation_window_size_tile16():\n",
    "    \"\"\"\n",
    "    Plot overall average quality across ALL user traces and network traces\n",
    "    for different allocation window sizes.\n",
    "    \n",
    "    Fixed: n_tile = 16\n",
    "    Hue: streaming_settings (2, 0, 1) representing (500, 1000, 2000) ms allocation window sizes \n",
    "    Averages over: 3 users  4 network traces = 12 combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    cfg = STREAMING_CONFIG\n",
    "    output_dir = cfg['output_base'] / 'line_plots' / 'allocation_window' / cfg['scene']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    FPS = 30.0  # Frames per second\n",
    "    \n",
    "    # Fixed tile configuration\n",
    "    N_TILE = 16\n",
    "    \n",
    "    # Define streaming settings with their configurations for allocation window sizes\n",
    "    streaming_configs = [\n",
    "        {'setting': 'streaming_2', 'label': '500', 'color': color_palette[0]},\n",
    "        {'setting': 'streaming_0', 'label': '1000', 'color': color_palette[1]},\n",
    "        {'setting': 'streaming_1', 'label': '2000', 'color': color_palette[2]},\n",
    "    ]\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in cfg['metrics'].items():\n",
    "        fig, ax = plt.subplots(figsize=(9.6, 4.8))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Allocation Window Size Average {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Plot each streaming configuration averaged across ALL combinations\n",
    "        for stream_cfg in streaming_configs:\n",
    "            streaming_setting = stream_cfg['setting']\n",
    "            \n",
    "            # Collect data from all user-network combinations\n",
    "            all_combinations_data = []\n",
    "            \n",
    "            for user_trace in cfg['user_traces']:\n",
    "                for network_trace in cfg['network_traces']:\n",
    "                    data_path = get_streaming_path(\n",
    "                        cfg['scene'], cfg['policy'], cfg['budget'], \n",
    "                        cfg['iteration'], N_TILE, user_trace, \n",
    "                        network_trace, streaming_setting, \n",
    "                        cfg['iteration']\n",
    "                    )\n",
    "                    \n",
    "                    metric_file = data_path / metric_info['file']\n",
    "                    \n",
    "                    if metric_file.exists():\n",
    "                        data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                        if data:\n",
    "                            all_combinations_data.append(data)\n",
    "                            print(f\"  Loaded: {user_trace}/{network_trace}/{streaming_setting} - {len(data)} frames\")\n",
    "                    else:\n",
    "                        print(f\"  [WARN] Not found: {user_trace}/{network_trace}/{streaming_setting}\")\n",
    "            \n",
    "            if all_combinations_data:\n",
    "                # Find common frames across all combinations\n",
    "                all_frames = set(all_combinations_data[0].keys())\n",
    "                for data in all_combinations_data[1:]:\n",
    "                    all_frames &= set(data.keys())\n",
    "                all_frames = sorted(all_frames)\n",
    "                \n",
    "                # Convert frames to time (seconds)\n",
    "                all_times = [frame / FPS for frame in all_frames]\n",
    "                \n",
    "                means = []\n",
    "                \n",
    "                for frame in all_frames:\n",
    "                    frame_values = [data[frame] for data in all_combinations_data if frame in data]\n",
    "                    if frame_values:\n",
    "                        means.append(np.mean(frame_values))\n",
    "                \n",
    "                means = np.array(means)\n",
    "                \n",
    "                # Plot mean line only (no markers)\n",
    "                ax.plot(all_times, means,\n",
    "                       linewidth=2, color=stream_cfg['color'],\n",
    "                       label=stream_cfg['label'], zorder=2)\n",
    "                \n",
    "                print(f\"\\n  {stream_cfg['label']} overall average:\")\n",
    "                print(f\"    Combinations: {len(all_combinations_data)}\")\n",
    "                print(f\"    Frames: {len(all_frames)}\")\n",
    "                print(f\"    Mean: {np.mean(means):.2f}\")\n",
    "            else:\n",
    "                print(f\"  [ERROR] No data found for {stream_cfg['label']}\")\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Time (seconds)', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        \n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        ax.set_xlim(left=-0.5, right=30.5)\n",
    "        if metric_key == 'VMAF':\n",
    "            ax.set_ylim(bottom=-1, top=101)\n",
    "        elif metric_key == 'SSIM':\n",
    "            ax.set_ylim(top=1.01)\n",
    "        elif metric_key == 'PSNR':\n",
    "            ax.set_ylim(bottom=0)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        # Save\n",
    "        base_name = f'{metric_key}_allocation_window_average_tile{N_TILE}'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\n  Saved: {base_name}.png and .eps\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Run the plot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Allocation Window Size Plot (1 plot per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_allocation_window_size_tile16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55196863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_allocation_window_overall_by_tiles():\n",
    "    \"\"\"\n",
    "    Plot overall average quality across ALL user traces and network traces\n",
    "    for different allocation window sizes.\n",
    "    \n",
    "    x-axis: number of tiles (1, 4, 16)\n",
    "    y-axis: quality (PSNR/SSIM/VMAF)\n",
    "    Hue: streaming_settings (2, 0, 1) representing (500, 1000, 2000) ms allocation window sizes\n",
    "    Averages over: 3 users  4 network traces = 12 combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    cfg = STREAMING_CONFIG\n",
    "    output_dir = cfg['output_base'] / 'bar_plots' / 'allocation_window_tiles' / cfg['scene']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define streaming settings with their configurations for allocation window sizes\n",
    "    streaming_configs = [\n",
    "        {'setting': 'streaming_2', 'label': '500 ms', 'color': color_palette[0]},\n",
    "        {'setting': 'streaming_0', 'label': '1000 ms', 'color': color_palette[1]},\n",
    "        {'setting': 'streaming_1', 'label': '2000 ms', 'color': color_palette[2]},\n",
    "    ]\n",
    "    \n",
    "    # Tile configurations to test\n",
    "    tile_configs = [1, 4, 16]\n",
    "    \n",
    "    # For each metric\n",
    "    for metric_key, metric_info in cfg['metrics'].items():\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Plotting Allocation Window by Tiles - {metric_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # x-axis labels\n",
    "        x_labels = [str(n) for n in tile_configs]\n",
    "        n_groups = len(x_labels)\n",
    "        n_windows = len(streaming_configs)\n",
    "        \n",
    "        # Bar positions\n",
    "        x_pos = np.arange(n_groups) * (n_windows * bar_width + bar_space)\n",
    "        \n",
    "        # Collect data for each streaming configuration\n",
    "        for stream_idx, stream_cfg in enumerate(streaming_configs):\n",
    "            streaming_setting = stream_cfg['setting']\n",
    "            \n",
    "            group_means = []\n",
    "            group_stds = []\n",
    "            \n",
    "            # For each tile configuration\n",
    "            for n_tile in tile_configs:\n",
    "                tile_values = []\n",
    "                \n",
    "                # Collect data from all user-network combinations\n",
    "                for user_trace in cfg['user_traces']:\n",
    "                    for network_trace in cfg['network_traces']:\n",
    "                        data_path = get_streaming_path(\n",
    "                            cfg['scene'], cfg['policy'], cfg['budget'],\n",
    "                            cfg['iteration'], n_tile, user_trace,\n",
    "                            network_trace, streaming_setting,\n",
    "                            cfg['iteration']\n",
    "                        )\n",
    "                        \n",
    "                        metric_file = data_path / metric_info['file']\n",
    "                        \n",
    "                        if metric_file.exists():\n",
    "                            data = metric_info['parser'](metric_file, metric_type=metric_key.lower())\n",
    "                            if data:\n",
    "                                # Average over all frames for this combination\n",
    "                                combination_avg = np.mean(list(data.values()))\n",
    "                                tile_values.append(combination_avg)\n",
    "                        else:\n",
    "                            print(f\"  [WARN] Not found: tile{n_tile}/{user_trace}/{network_trace}/{streaming_setting}\")\n",
    "                \n",
    "                # Calculate mean and stderr for this tile configuration\n",
    "                if tile_values:\n",
    "                    mean_val = np.mean(tile_values)\n",
    "                    std_val = np.std(tile_values)\n",
    "                    stderr = std_val / np.sqrt(len(tile_values))\n",
    "                    \n",
    "                    group_means.append(mean_val)\n",
    "                    group_stds.append(stderr)\n",
    "                    \n",
    "                    print(f\"  Tile {n_tile} - {stream_cfg['label']}: \"\n",
    "                          f\"mean={mean_val:.2f}, std={std_val:.2f}, n={len(tile_values)}\")\n",
    "                else:\n",
    "                    group_means.append(0)\n",
    "                    group_stds.append(0)\n",
    "                    print(f\"  [ERROR] No data for tile {n_tile} - {stream_cfg['label']}\")\n",
    "            \n",
    "            # Plot bars\n",
    "            offset = stream_idx * (bar_width + bar_btw_space)\n",
    "            ax.bar(x_pos + offset, group_means, bar_width,\n",
    "                   yerr=group_stds, capsize=err_capsize,\n",
    "                   label=stream_cfg['label'], color=stream_cfg['color'],\n",
    "                   error_kw={'elinewidth': err_lw, 'capthick': err_capthick})\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Number of Tiles', fontsize=20)\n",
    "        ax.set_ylabel(f\"Quality in {metric_info['ylabel']}\", fontsize=20)\n",
    "        ax.set_xticks(x_pos + (n_windows - 1) * (bar_width + bar_btw_space) / 2)\n",
    "        ax.set_xticklabels(x_labels, fontsize=18)\n",
    "        ax.legend(loc='best', framealpha=0.9, fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        # Set y-axis limits based on metric\n",
    "        if metric_key == 'VMAF':\n",
    "            ax.set_ylim(bottom=0, top=100)\n",
    "        elif metric_key == 'SSIM':\n",
    "            ax.set_ylim(top=1.01)\n",
    "        elif metric_key == 'PSNR':\n",
    "            ax.set_ylim(bottom=0)\n",
    "        \n",
    "        fig.set_constrained_layout(True)\n",
    "        \n",
    "        # Save\n",
    "        base_name = f'{metric_key}_allocation_window_by_tiles_budget{cfg[\"budget\"]//1000}K'\n",
    "        plt.savefig(output_dir / f'{base_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(output_dir / f'{base_name}.eps', format='eps', bbox_inches='tight')\n",
    "        print(f\"\\n  Saved: {base_name}.png and .eps\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Run the plot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Allocation Window by Tiles Plot (1 plot per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_allocation_window_overall_by_tiles()\n",
    "# Run the plot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Concurrent Streams by Tiles Plot (1 plot per metric)\")\n",
    "print(\"=\"*60)\n",
    "plot_allocation_window_overall_by_tiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192161d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshsplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
